{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)import os\nimport zipfile\nimport glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torchvision\nfrom torchvision import datasets, transforms\nimport random\nrandom_state = 2137\nnp.random.seed(random_state)\ntorch.manual_seed(random_state)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:14:58.125056Z","iopub.execute_input":"2024-02-09T12:14:58.125748Z","iopub.status.idle":"2024-02-09T12:14:58.140941Z","shell.execute_reply.started":"2024-02-09T12:14:58.125694Z","shell.execute_reply":"2024-02-09T12:14:58.138327Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f86faa20bd0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# loading datasets","metadata":{}},{"cell_type":"code","source":"#reading csv\nannotations = pd.read_csv('../input/cats-and-dogs-breeds-classification-oxford-dataset/annotations/annotations/list.txt')\n\n#The first 4 rows consists of the information about breeds\n#Reading the data after 5th row\nannotations = annotations.loc[5:,]\n\n#Processing the columns\nannotations[['CLASS-ID','SPECIES','BREED','ID']] = annotations['#Image CLASS-ID SPECIES BREED ID'].str.split(expand=True) \n\n#Dropping unnecessary columns\nannotations = annotations.drop('#Image CLASS-ID SPECIES BREED ID',axis=1)\n\n#renaming the columns\nannotations = annotations.rename(columns={\"CLASS-ID\": \"image\", \"SPECIES\": \"CLASS-ID\", 'BREED' : \"SPECIES\", \"ID\":\"BREED ID\"})\n\n\n#converting the object type to int type\nannotations[[\"CLASS-ID\",\"SPECIES\",\"BREED ID\"]] = annotations[[\"CLASS-ID\",\"SPECIES\",\"BREED ID\"]].astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:14:58.145591Z","iopub.execute_input":"2024-02-09T12:14:58.146363Z","iopub.status.idle":"2024-02-09T12:14:58.247448Z","shell.execute_reply.started":"2024-02-09T12:14:58.146298Z","shell.execute_reply":"2024-02-09T12:14:58.244447Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"annotations","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:14:58.250283Z","iopub.execute_input":"2024-02-09T12:14:58.250876Z","iopub.status.idle":"2024-02-09T12:14:58.267543Z","shell.execute_reply.started":"2024-02-09T12:14:58.250831Z","shell.execute_reply":"2024-02-09T12:14:58.266267Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"                     image  CLASS-ID  SPECIES  BREED ID\n5           Abyssinian_100         1        1         1\n6           Abyssinian_101         1        1         1\n7           Abyssinian_102         1        1         1\n8           Abyssinian_103         1        1         1\n9           Abyssinian_104         1        1         1\n...                    ...       ...      ...       ...\n7349  yorkshire_terrier_96        37        2        25\n7350  yorkshire_terrier_97        37        2        25\n7351  yorkshire_terrier_98        37        2        25\n7352  yorkshire_terrier_99        37        2        25\n7353   yorkshire_terrier_9        37        2        25\n\n[7349 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>CLASS-ID</th>\n      <th>SPECIES</th>\n      <th>BREED ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>Abyssinian_100</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Abyssinian_101</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Abyssinian_102</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Abyssinian_103</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Abyssinian_104</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7349</th>\n      <td>yorkshire_terrier_96</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7350</th>\n      <td>yorkshire_terrier_97</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7351</th>\n      <td>yorkshire_terrier_98</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7352</th>\n      <td>yorkshire_terrier_99</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7353</th>\n      <td>yorkshire_terrier_9</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n<p>7349 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Species stands here for dog (2) or a cat (1), breed ID is the ID of a breed given we know what type of animal it is, and class-ID is a unique ID for each species and breed together. Overall there is 25 cats breeds and 12 dog breeds. image is a column of filenames. All the files here are in jpg format","metadata":{}},{"cell_type":"markdown","source":"### RUN THIS CELL ONLY ONCE!!!","metadata":{}},{"cell_type":"code","source":"# adding the extension to image so it can be used to access the real image\nannotations['image'] = annotations['image'].apply(lambda x : str(x)+'.jpg')\nannotations = annotations.reset_index()\nannotations = annotations.drop('index',axis=1)\n\n#Extracting the classname/breed of the animal\nannotations['classname'] = annotations['image'].apply(lambda x: str(x)[:str(x).rindex('_')])\n\n# Adding information about cat or dog based on the 'Species' column to the 'classname' column\nannotations['classname'] = annotations.apply(lambda row: f\"{('dog' if row['SPECIES'] == 2 else 'cat')}_{row['classname']}\", axis=1)\nannotations","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:14:58.269139Z","iopub.execute_input":"2024-02-09T12:14:58.269635Z","iopub.status.idle":"2024-02-09T12:14:58.411663Z","shell.execute_reply.started":"2024-02-09T12:14:58.269598Z","shell.execute_reply":"2024-02-09T12:14:58.410278Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"                         image  CLASS-ID  SPECIES  BREED ID  \\\n0           Abyssinian_100.jpg         1        1         1   \n1           Abyssinian_101.jpg         1        1         1   \n2           Abyssinian_102.jpg         1        1         1   \n3           Abyssinian_103.jpg         1        1         1   \n4           Abyssinian_104.jpg         1        1         1   \n...                        ...       ...      ...       ...   \n7344  yorkshire_terrier_96.jpg        37        2        25   \n7345  yorkshire_terrier_97.jpg        37        2        25   \n7346  yorkshire_terrier_98.jpg        37        2        25   \n7347  yorkshire_terrier_99.jpg        37        2        25   \n7348   yorkshire_terrier_9.jpg        37        2        25   \n\n                  classname  \n0            cat_Abyssinian  \n1            cat_Abyssinian  \n2            cat_Abyssinian  \n3            cat_Abyssinian  \n4            cat_Abyssinian  \n...                     ...  \n7344  dog_yorkshire_terrier  \n7345  dog_yorkshire_terrier  \n7346  dog_yorkshire_terrier  \n7347  dog_yorkshire_terrier  \n7348  dog_yorkshire_terrier  \n\n[7349 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>CLASS-ID</th>\n      <th>SPECIES</th>\n      <th>BREED ID</th>\n      <th>classname</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abyssinian_100.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>cat_Abyssinian</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Abyssinian_101.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>cat_Abyssinian</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Abyssinian_102.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>cat_Abyssinian</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Abyssinian_103.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>cat_Abyssinian</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Abyssinian_104.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>cat_Abyssinian</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7344</th>\n      <td>yorkshire_terrier_96.jpg</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>dog_yorkshire_terrier</td>\n    </tr>\n    <tr>\n      <th>7345</th>\n      <td>yorkshire_terrier_97.jpg</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>dog_yorkshire_terrier</td>\n    </tr>\n    <tr>\n      <th>7346</th>\n      <td>yorkshire_terrier_98.jpg</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>dog_yorkshire_terrier</td>\n    </tr>\n    <tr>\n      <th>7347</th>\n      <td>yorkshire_terrier_99.jpg</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>dog_yorkshire_terrier</td>\n    </tr>\n    <tr>\n      <th>7348</th>\n      <td>yorkshire_terrier_9.jpg</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>dog_yorkshire_terrier</td>\n    </tr>\n  </tbody>\n</table>\n<p>7349 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Creating the dataset class to make the data easily accesable","metadata":{}},{"cell_type":"code","source":"class CatsDogsDataset(Dataset):\n    def __init__(self, file_list, transform=None):\n        self.folder_patch = '/kaggle/input/cats-and-dogs-breeds-classification-oxford-dataset/images/images/'\n        self.annotations = file_list\n        self.transform = transform\n        self.filelength = len(file_list)\n\n    def __len__(self):\n        return self.filelength\n\n    def __getitem__(self, idx):\n        classID = self.annotations['CLASS-ID'].iloc[idx]\n        img_path = self.annotations['image'].iloc[idx]\n        img_path = self.folder_patch + img_path\n        img = Image.open(img_path)\n        \n        has_alpha_channel = img.mode == 'RGBA'\n        if has_alpha_channel == True:\n            print(\"image has Alpha channel\")\n            img = img.convert('RGB')\n        if self.transform is not None:\n            try:\n                img = self.transform(img)\n            except RuntimeError as e:\n                print(f\"Exception: {e}\")\n                print(\"Shape before normalization:\", img.size)\n                print(img_path)\n                tot = transforms.ToTensor()\n                img_tensor = tot(img)\n                print(\"Input Tensor Shape:\", img_tensor.shape)\n                print(\"Input Tensor Values:\", img_tensor)\n        #else:\n            #print(\"No transformations to be done\")\n        return img, classID-1","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:14:58.414619Z","iopub.execute_input":"2024-02-09T12:14:58.415156Z","iopub.status.idle":"2024-02-09T12:14:58.427003Z","shell.execute_reply.started":"2024-02-09T12:14:58.415122Z","shell.execute_reply":"2024-02-09T12:14:58.425368Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"all_images = CatsDogsDataset(annotations)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:14:58.429759Z","iopub.execute_input":"2024-02-09T12:14:58.430849Z","iopub.status.idle":"2024-02-09T12:14:58.441015Z","shell.execute_reply.started":"2024-02-09T12:14:58.430755Z","shell.execute_reply":"2024-02-09T12:14:58.439568Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"# Plotting sample images","metadata":{}},{"cell_type":"code","source":"num_images = 4\nplt.figure(figsize=(10, 5))\nfor i in range(num_images):\n    idx = random.randint(0, len(all_images) - 1)\n    image, classID = all_images[idx]\n    classname = all_images.annotations['classname'].iloc[idx]\n    # Convert PIL Image to PyTorch tensor and permute dimensions\n    image = TF.to_pil_image(image)  # Convert to PIL Image\n    plt.subplot(2, num_images//2, i+1)\n    plt.imshow(image)\n    plt.title(classname)\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:16:47.466815Z","iopub.execute_input":"2024-02-09T12:16:47.468443Z","iopub.status.idle":"2024-02-09T12:16:47.534968Z","shell.execute_reply.started":"2024-02-09T12:16:47.468376Z","shell.execute_reply":"2024-02-09T12:16:47.532938Z"},"trusted":true},"execution_count":72,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[72], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m classname \u001b[38;5;241m=\u001b[39m all_images\u001b[38;5;241m.\u001b[39mannotations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Convert PIL Image to PyTorch tensor and permute dimensions\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mTF\u001b[49m\u001b[38;5;241m.\u001b[39mto_pil_image(image)  \u001b[38;5;66;03m# Convert to PIL Image\u001b[39;00m\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m, num_images\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image)\n","\u001b[0;31mNameError\u001b[0m: name 'TF' is not defined"],"ename":"NameError","evalue":"name 'TF' is not defined","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 0 Axes>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Analysis of image resolutions (I couldn't find any information about it in a dataset desription)","metadata":{}},{"cell_type":"code","source":"dataset_size = len(all_images)\nprint(dataset_size)\nimage_sizes = []\nfor i in range(dataset_size):\n    img, _ = all_images[i]\n    image_sizes.append(img.size)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:14:58.698511Z","iopub.status.idle":"2024-02-09T12:14:58.699818Z","shell.execute_reply.started":"2024-02-09T12:14:58.699528Z","shell.execute_reply":"2024-02-09T12:14:58.699563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 3 images in a dataset that have an additional alpha channel, what needs to be considered while handling with  teh images","metadata":{}},{"cell_type":"code","source":"unique_count = len(set(image_sizes)) \nprint(\"Number of unique elements:\", unique_count)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:14:58.701815Z","iopub.status.idle":"2024-02-09T12:14:58.702494Z","shell.execute_reply.started":"2024-02-09T12:14:58.702164Z","shell.execute_reply":"2024-02-09T12:14:58.702208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are many different sizes of images","metadata":{}},{"cell_type":"code","source":"x_values, y_values = zip(*image_sizes)\n\nplt.title('x_values') \nplt.hist(x_values,bins=100) \nplt.show()\n\nplt.title('y_values')\nplt.hist(y_values,bins=100)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:14:58.704392Z","iopub.status.idle":"2024-02-09T12:14:58.705055Z","shell.execute_reply.started":"2024-02-09T12:14:58.704735Z","shell.execute_reply":"2024-02-09T12:14:58.704761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"resoulutions above 1000 pixels in one axis are not representative","metadata":{}},{"cell_type":"markdown","source":"## 2D histogram is a very useful tool to give the insight what is the distribution of resolutions. It also visualizes what are the image shapes","metadata":{}},{"cell_type":"code","source":"filtered_data = [(x, y) for x, y in image_sizes if x < 1000 and y < 1000]\n\nx_values, y_values = zip(*filtered_data)\nplt.hist2d(x_values, y_values, bins=(50, 50), cmap='viridis', cmin = 1)\n\nplt.xlim(0, 1000)\nplt.ylim(0, 1000)\n\n# Add color bar for reference\ncbar = plt.colorbar()\ncbar.set_label('Frequency')\n\n# Add labels and title\nplt.xlabel('horizontal')\nplt.ylabel('vertical')\nplt.title('2D Histogram for resolutions')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:14:58.707108Z","iopub.status.idle":"2024-02-09T12:14:58.707785Z","shell.execute_reply.started":"2024-02-09T12:14:58.707471Z","shell.execute_reply":"2024-02-09T12:14:58.707498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of the images have rectangular shapes with proportions around 5x4 or 3x5 which should be also true in real life scenarions","metadata":{}},{"cell_type":"markdown","source":"### Let's have a closer look:","metadata":{}},{"cell_type":"code","source":"hist, x_edges, y_edges, _ = plt.hist2d(x_values, y_values, bins=(30, 30), cmap='inferno', cmin = 1, vmax=30)\n\nplt.xlim(0, 1000)\nplt.ylim(0, 1000)\n\n# Add color bar for reference\ncbar = plt.colorbar()\ncbar.set_label('Frequency')\n\ncbar.set_ticks([0, 2, 4, 6, 10, 20, 30])\n\nplt.xlabel('horizontal')\nplt.ylabel('vertical')\nplt.title('2D Histogram for rare resolutions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:14:58.710274Z","iopub.status.idle":"2024-02-09T12:14:58.710800Z","shell.execute_reply.started":"2024-02-09T12:14:58.710565Z","shell.execute_reply":"2024-02-09T12:14:58.710582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It can be observed that resolutions below 250 and 550 pixels in any axis also appear rarely","metadata":{}},{"cell_type":"markdown","source":"# Plotting the distribution of animal breed to check if they are really distributed uniformally","metadata":{}},{"cell_type":"code","source":"plt.hist(annotations['classname'], bins=37, edgecolor='black',rwidth=0.5)\nplt.xticks(rotation='vertical')\nplt.xlabel('breed indexes')\nplt.ylabel('Frequency')\nplt.title('Frequency of different breeds in dataset')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:14:58.712347Z","iopub.status.idle":"2024-02-09T12:14:58.712735Z","shell.execute_reply.started":"2024-02-09T12:14:58.712564Z","shell.execute_reply":"2024-02-09T12:14:58.712579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The breeds are actually almost uniformally distributed","metadata":{}}]}