{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":325302,"sourceType":"datasetVersion","datasetId":137362},{"sourceId":7520479,"sourceType":"datasetVersion","datasetId":4380888}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{"_uuid":"f5b41e5a-0d11-449c-a5c9-477b57a65a9a","_cell_guid":"f05ac9cf-11a9-46d6-95a7-baf6d0ac38ee","trusted":true}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n #   for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"0d7d39d3-a752-4ac3-a9f1-da293f88a4c9","_cell_guid":"a8c5fae8-0f13-4278-9a41-2935660089ba","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-02-05T13:43:48.727535Z","iopub.execute_input":"2024-02-05T13:43:48.732465Z","iopub.status.idle":"2024-02-05T13:43:49.174248Z","shell.execute_reply.started":"2024-02-05T13:43:48.732413Z","shell.execute_reply":"2024-02-05T13:43:49.173319Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import zipfile\nimport glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nfrom torchvision import datasets, transforms\nimport torchvision.models as models\nfrom datetime import datetime\nimport wandb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nrandom_state = 2137\nnp.random.seed(random_state)\ntorch.manual_seed(random_state)\ntorch.cuda.manual_seed(random_state)","metadata":{"_uuid":"dd292565-8513-47b8-a2c6-7a4977473de4","_cell_guid":"6fafdea2-41e8-4cf1-9a6a-f64db210ca65","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-02-05T13:43:49.175970Z","iopub.execute_input":"2024-02-05T13:43:49.176450Z","iopub.status.idle":"2024-02-05T13:43:53.929593Z","shell.execute_reply.started":"2024-02-05T13:43:49.176416Z","shell.execute_reply":"2024-02-05T13:43:53.928618Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"os.environ[\"WANDB_API_KEY\"] = 'cac5e1e8113d6c2054d4bc95b0b518086be2b55d'","metadata":{"_uuid":"8d04d5bc-4435-4e39-b749-a60ca5a0d63e","_cell_guid":"d720493f-0c28-4daa-b44d-924b21a078fa","execution":{"iopub.status.busy":"2024-02-05T13:43:53.931045Z","iopub.execute_input":"2024-02-05T13:43:53.931332Z","iopub.status.idle":"2024-02-05T13:43:53.935363Z","shell.execute_reply.started":"2024-02-05T13:43:53.931308Z","shell.execute_reply":"2024-02-05T13:43:53.934388Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Initialising the project on wandb","metadata":{"_uuid":"54ff73d3-4361-4fb4-aa49-47982d5f86a4","_cell_guid":"49971fda-7849-46de-a925-f87b76c08dfc","trusted":true}},{"cell_type":"code","source":"def initialize_wandb(sweep_config):\n    current_time = datetime.now().strftime(\"%m-%d_%H:%M\")\n    #info = my_config.get_configuration_info()\n    run_name = f\"tuning_{current_time}\"\n    #print(run_name)\n    wandb.init()\n    #wandb.init(project='cats&dogs_ML&DL_project', save_code=True, config = sweep_config, name = run_name)\n    return","metadata":{"_uuid":"40e08122-5bde-451d-8a5d-1efc92f138a3","_cell_guid":"624d8b13-c4e8-47cd-aaa0-136330fd2c22","execution":{"iopub.status.busy":"2024-02-05T13:43:53.937904Z","iopub.execute_input":"2024-02-05T13:43:53.938191Z","iopub.status.idle":"2024-02-05T13:43:53.950384Z","shell.execute_reply.started":"2024-02-05T13:43:53.938159Z","shell.execute_reply":"2024-02-05T13:43:53.949513Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Parameters","metadata":{"_uuid":"d9b755a5-9bed-4d0c-9379-ada101ebb874","_cell_guid":"60f41da9-366c-4dd9-bff6-9f915e9f23db","trusted":true}},{"cell_type":"code","source":"class configuration:\n    def __init__(self, sweep_config, model, model_transforms, last_checkpoint_path=None):\n        config = wandb.init().config\n        self.last_checkpoint_path = last_checkpoint_path\n        self.model = model\n        print(\"loading parameters\")\n        self.batch_size = config.batch_size\n        print(\"batch\")\n        self.init_learning_rate = config.learning_rate\n        print(\"lr\")\n        self.optimizer_name = config.optimizer\n        print(\"optimizer\")\n        print(\"loaded parameters\")\n        self.optimizer = self.initialize_optimizer()\n        print(\"got optimizer\")\n        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min', patience=3, verbose=True, min_lr=self.init_learning_rate/32, factor=0.5)\n        self.criterion = nn.CrossEntropyLoss()\n        \n        self.test_transforms = model_transforms\n        # combine with some basic transforms\n        self.custom_transforms = get_costum_transforms()\n        self.train_transforms = transforms.Compose([self.custom_transforms,model_transforms])\n    def initialize_optimizer(self):\n        print(\"getting optimizer\")\n        if self.optimizer_name == 'sgd':\n            optimizer = optim.SGD(self.model.parameters(), lr=self.init_learning_rate, momentum=0.9)\n            print('sgd')\n        elif self.optimizer_name == 'adam':\n            optimizer = optim.Adam(self.model.parameters(), lr=self.init_learning_rate)\n            print('adam')\n        else:\n            print(\"Unsupported optimizer:\")\n            raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n        return optimizer\n    def get_configuration_info(self):\n        info = f\"{type(self.model).__name__}_\"\n        info += f\"{type(self.optimizer).__name__}_\"\n        info += f\"Batch={self.batch_size}_\"\n        info += f\"lr={self.optimizer.param_groups[0]['lr']}\"\n        return info\n    def get_configuration_dictionary(self):\n        configuration_info = {\n            'model_type': type(self.model).__name__,\n            'criterion': str(self.criterion),\n            'optimizer': type(self.optimizer).__name__,\n            'batch_size': self.batch_size,\n            'scheduler': type(self.scheduler).__name__,\n            'optimizer_params': {\n                'initial_lr': self.optimizer.param_groups[0]['lr']\n            },\n            'scheduler_params': {\n                'min_lr': self.scheduler.min_lrs,\n                'patience': self.scheduler.patience,\n                'factor': self.scheduler.factor\n            },\n            'custom_transforms': [str(transform) for transform in self.custom_transforms.transforms] if self.custom_transforms else None\n        }\n\n        return configuration_info","metadata":{"_uuid":"07422de6-5aab-495c-b98c-a5d8339a27af","_cell_guid":"46ec50f0-1641-4f1b-8c0e-af6d444070cd","_kg_hide-output":false,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-02-05T13:43:53.951517Z","iopub.execute_input":"2024-02-05T13:43:53.951877Z","iopub.status.idle":"2024-02-05T13:43:53.967010Z","shell.execute_reply.started":"2024-02-05T13:43:53.951822Z","shell.execute_reply":"2024-02-05T13:43:53.966195Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# loading datasets","metadata":{"_uuid":"3dcf512b-4e5c-413c-aad3-0028f8be4fe0","_cell_guid":"fd3174c1-4aee-4e29-bf1c-2c8b175f5bc8","trusted":true}},{"cell_type":"code","source":"#reading csv\nannotations = pd.read_csv('../input/cats-and-dogs-breeds-classification-oxford-dataset/annotations/annotations/list.txt')\n\n#The first 4 rows consists of the information about breeds\n#Reading the data after 5th row\nannotations = annotations.loc[5:,]\n\n#Processing the columns\nannotations[['CLASS-ID','SPECIES','BREED','ID']] = annotations['#Image CLASS-ID SPECIES BREED ID'].str.split(expand=True) \n\n#Dropping unnecessary columns\nannotations = annotations.drop('#Image CLASS-ID SPECIES BREED ID',axis=1)\n\n#renaming the columns\nannotations = annotations.rename(columns={\"CLASS-ID\": \"image\", \"SPECIES\": \"CLASS-ID\", 'BREED' : \"SPECIES\", \"ID\":\"BREED ID\"})\n\n\n#converting the object type to int type\nannotations[[\"CLASS-ID\",\"SPECIES\",\"BREED ID\"]] = annotations[[\"CLASS-ID\",\"SPECIES\",\"BREED ID\"]].astype(int)","metadata":{"_uuid":"c83b9513-15a6-426a-bcb4-9dd800a72898","_cell_guid":"d1d10af1-daa4-443b-87ab-1694cd1d502d","execution":{"iopub.status.busy":"2024-02-05T13:43:53.968096Z","iopub.execute_input":"2024-02-05T13:43:53.968447Z","iopub.status.idle":"2024-02-05T13:43:54.044278Z","shell.execute_reply.started":"2024-02-05T13:43:53.968410Z","shell.execute_reply":"2024-02-05T13:43:54.043311Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"annotations","metadata":{"_uuid":"b4552eef-311b-4783-a6f2-d72d38ffa8ad","_cell_guid":"44213b49-56b3-42e6-b7e5-4b55d94f2e43","execution":{"iopub.status.busy":"2024-02-05T13:43:54.045572Z","iopub.execute_input":"2024-02-05T13:43:54.045955Z","iopub.status.idle":"2024-02-05T13:43:54.062609Z","shell.execute_reply.started":"2024-02-05T13:43:54.045921Z","shell.execute_reply":"2024-02-05T13:43:54.061703Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                     image  CLASS-ID  SPECIES  BREED ID\n5           Abyssinian_100         1        1         1\n6           Abyssinian_101         1        1         1\n7           Abyssinian_102         1        1         1\n8           Abyssinian_103         1        1         1\n9           Abyssinian_104         1        1         1\n...                    ...       ...      ...       ...\n7349  yorkshire_terrier_96        37        2        25\n7350  yorkshire_terrier_97        37        2        25\n7351  yorkshire_terrier_98        37        2        25\n7352  yorkshire_terrier_99        37        2        25\n7353   yorkshire_terrier_9        37        2        25\n\n[7349 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>CLASS-ID</th>\n      <th>SPECIES</th>\n      <th>BREED ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>Abyssinian_100</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Abyssinian_101</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Abyssinian_102</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Abyssinian_103</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Abyssinian_104</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7349</th>\n      <td>yorkshire_terrier_96</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7350</th>\n      <td>yorkshire_terrier_97</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7351</th>\n      <td>yorkshire_terrier_98</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7352</th>\n      <td>yorkshire_terrier_99</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>7353</th>\n      <td>yorkshire_terrier_9</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n<p>7349 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Species stands here for dog (2) or a cat (1), breed ID is the ID of a breed given we know what type of animal it is, and class-ID is a unique ID for each species and breed together. Overall there is 25 cats breeds and 12 dog breeds. image is a column of filenames. All the files here are in jpg format","metadata":{"_uuid":"06ab5418-056c-414c-bf79-c43ee63882f3","_cell_guid":"2d64c844-43a0-43d1-ada8-15f49bc395c8","trusted":true}},{"cell_type":"markdown","source":"### RUN THIS CELL ONLY ONCE!!!","metadata":{"_uuid":"5d3184df-d2c8-4cda-8b1b-7784f9c6253e","_cell_guid":"25c82c4e-bf8c-4e06-af65-7b43aaf665c6","trusted":true}},{"cell_type":"code","source":"# adding the extension to image so it can be used to access the real image\nannotations['image'] = annotations['image'].apply(lambda x : str(x)+'.jpg')\nannotations = annotations.reset_index()\nannotations = annotations.drop('index',axis=1)\n\n#Extracting the classname/breed of the animal\nannotations['classname'] = annotations['image'].apply(lambda x: str(x)[:str(x).rindex('_')])\n\n# Adding information about cat or dog based on the 'Species' column to the 'classname' column\nannotations['classname'] = annotations.apply(lambda row: f\"{('dog' if row['SPECIES'] == 2 else 'cat')}_{row['classname']}\", axis=1)\nannotations","metadata":{"_uuid":"a65a197e-9037-43a1-b283-e715416793a1","_cell_guid":"ddc198d8-0457-4df8-9ae9-1c5b81591540","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-02-05T13:43:54.064007Z","iopub.execute_input":"2024-02-05T13:43:54.064743Z","iopub.status.idle":"2024-02-05T13:43:54.198993Z","shell.execute_reply.started":"2024-02-05T13:43:54.064707Z","shell.execute_reply":"2024-02-05T13:43:54.198035Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                         image  CLASS-ID  SPECIES  BREED ID  \\\n0           Abyssinian_100.jpg         1        1         1   \n1           Abyssinian_101.jpg         1        1         1   \n2           Abyssinian_102.jpg         1        1         1   \n3           Abyssinian_103.jpg         1        1         1   \n4           Abyssinian_104.jpg         1        1         1   \n...                        ...       ...      ...       ...   \n7344  yorkshire_terrier_96.jpg        37        2        25   \n7345  yorkshire_terrier_97.jpg        37        2        25   \n7346  yorkshire_terrier_98.jpg        37        2        25   \n7347  yorkshire_terrier_99.jpg        37        2        25   \n7348   yorkshire_terrier_9.jpg        37        2        25   \n\n                  classname  \n0            cat_Abyssinian  \n1            cat_Abyssinian  \n2            cat_Abyssinian  \n3            cat_Abyssinian  \n4            cat_Abyssinian  \n...                     ...  \n7344  dog_yorkshire_terrier  \n7345  dog_yorkshire_terrier  \n7346  dog_yorkshire_terrier  \n7347  dog_yorkshire_terrier  \n7348  dog_yorkshire_terrier  \n\n[7349 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>CLASS-ID</th>\n      <th>SPECIES</th>\n      <th>BREED ID</th>\n      <th>classname</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abyssinian_100.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>cat_Abyssinian</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Abyssinian_101.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>cat_Abyssinian</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Abyssinian_102.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>cat_Abyssinian</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Abyssinian_103.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>cat_Abyssinian</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Abyssinian_104.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>cat_Abyssinian</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7344</th>\n      <td>yorkshire_terrier_96.jpg</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>dog_yorkshire_terrier</td>\n    </tr>\n    <tr>\n      <th>7345</th>\n      <td>yorkshire_terrier_97.jpg</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>dog_yorkshire_terrier</td>\n    </tr>\n    <tr>\n      <th>7346</th>\n      <td>yorkshire_terrier_98.jpg</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>dog_yorkshire_terrier</td>\n    </tr>\n    <tr>\n      <th>7347</th>\n      <td>yorkshire_terrier_99.jpg</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>dog_yorkshire_terrier</td>\n    </tr>\n    <tr>\n      <th>7348</th>\n      <td>yorkshire_terrier_9.jpg</td>\n      <td>37</td>\n      <td>2</td>\n      <td>25</td>\n      <td>dog_yorkshire_terrier</td>\n    </tr>\n  </tbody>\n</table>\n<p>7349 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Adding transformations","metadata":{"_uuid":"5de72031-2f24-4082-add2-78f5b2997138","_cell_guid":"e4c62191-d037-479d-8003-966d214df6bf","trusted":true}},{"cell_type":"code","source":"def get_costum_transforms():\n    costum_transforms = torchvision.transforms.Compose([\n        transforms.RandomRotation(degrees=(-30, 30),fill=None),\n        transforms.Resize((300,300)),\n        transforms.RandomApply([transforms.Compose([\n                transforms.CenterCrop(200),\n                transforms.RandomCrop(80),\n            ]),], p=0.3),\n        transforms.RandomHorizontalFlip(p=0.4),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1),\n        transforms.GaussianBlur(kernel_size=(5,5), sigma=0.3),\n        transforms.RandomApply([transforms.Compose([\n                transforms.GaussianBlur(kernel_size=(9,9), sigma=0.7),\n            ]),], p=0.4),\n      ])\n    return costum_transforms","metadata":{"_uuid":"014a9871-c116-4325-84d9-11d993cc832f","_cell_guid":"1e8ce57e-9537-46bd-93bd-6d48f4d05a30","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-02-05T13:43:54.200424Z","iopub.execute_input":"2024-02-05T13:43:54.200829Z","iopub.status.idle":"2024-02-05T13:43:54.209245Z","shell.execute_reply.started":"2024-02-05T13:43:54.200793Z","shell.execute_reply":"2024-02-05T13:43:54.208191Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"\n\n# Creating the dataset class to make it easily accessable and short data analysis","metadata":{"_uuid":"bc104db6-a1f3-4a07-941f-e6dd9a5683f0","_cell_guid":"01439d6b-2580-4a84-954a-b0e25a369a2a","trusted":true}},{"cell_type":"code","source":"class CatsDogsDataset(Dataset):\n    def __init__(self, file_list, transform=None):\n        self.folder_patch = '/kaggle/input/cats-and-dogs-breeds-classification-oxford-dataset/images/images/'\n        self.annotations = file_list\n        self.transform = transform\n        self.filelength = len(file_list)\n\n    def __len__(self):\n        return self.filelength\n\n    def __getitem__(self, idx):\n        classID = self.annotations['CLASS-ID'].iloc[idx]\n        img_path = self.annotations['image'].iloc[idx]\n        img_path = self.folder_patch + img_path\n        img = Image.open(img_path)\n        \n        has_alpha_channel = img.mode == 'RGBA'\n        if has_alpha_channel == True:\n            print(\"image has Alpha channel\")\n            img = img.convert('RGB')\n        if self.transform is not None:\n            try:\n                img = self.transform(img)\n            except RuntimeError as e:\n                print(f\"Exception: {e}\")\n                print(\"Shape before normalization:\", img.size)\n                print(img_path)\n                tot = transforms.ToTensor()\n                img_tensor = tot(img)\n                print(\"Input Tensor Shape:\", img_tensor.shape)\n                print(\"Input Tensor Values:\", img_tensor)\n        #else:\n            #print(\"No transformations to be done\")\n        return img, classID-1","metadata":{"_uuid":"678f73e2-736c-4b98-a6c4-d0084ff8955d","_cell_guid":"dc8cbeab-2d61-4464-be7e-ea5998ea135e","execution":{"iopub.status.busy":"2024-02-05T13:43:54.212949Z","iopub.execute_input":"2024-02-05T13:43:54.213345Z","iopub.status.idle":"2024-02-05T13:43:54.223155Z","shell.execute_reply.started":"2024-02-05T13:43:54.213311Z","shell.execute_reply":"2024-02-05T13:43:54.222245Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the histogram of images resolutions (I couldn't find any information about the images resolutions in a dataset)","metadata":{"_uuid":"727204d3-5ac6-4d85-8aae-ca7de7134422","_cell_guid":"06a3ed58-05c3-4bae-9846-f50508e0368d","trusted":true}},{"cell_type":"code","source":"all_images = CatsDogsDataset(annotations)","metadata":{"_uuid":"ca49b3cf-0779-4055-91f0-94e64feee06c","_cell_guid":"807c483d-7f9d-4b67-8537-178e9c284178","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-02-05T13:43:54.224223Z","iopub.execute_input":"2024-02-05T13:43:54.224544Z","iopub.status.idle":"2024-02-05T13:43:54.236971Z","shell.execute_reply.started":"2024-02-05T13:43:54.224508Z","shell.execute_reply":"2024-02-05T13:43:54.236002Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"dataset_size = len(all_images)\nprint(dataset_size)\nimage_sizes = []\nfor i in range(dataset_size):\n    img, _ = all_images[i]\n    image_sizes.append(img.size)","metadata":{"_uuid":"d8a39fa8-937e-4c17-b031-013fa883315d","_cell_guid":"68f4e428-2a28-47dd-a3d2-c45134509a4b","execution":{"iopub.status.busy":"2024-01-27T12:05:45.472305Z","iopub.execute_input":"2024-01-27T12:05:45.472759Z","iopub.status.idle":"2024-01-27T12:05:55.092793Z","shell.execute_reply.started":"2024-01-27T12:05:45.472702Z","shell.execute_reply":"2024-01-27T12:05:55.091935Z"},"trusted":true}},{"cell_type":"markdown","source":"unique_count = len(set(image_sizes))\nprint(\"Number of unique elements:\", unique_count)","metadata":{"_uuid":"f3f0e2f8-9298-493b-9574-ce937b10ce01","_cell_guid":"65c37f27-3a47-482f-9736-e9edd6363542","execution":{"iopub.status.busy":"2024-01-27T12:05:55.094222Z","iopub.execute_input":"2024-01-27T12:05:55.094919Z","iopub.status.idle":"2024-01-27T12:05:55.103210Z","shell.execute_reply.started":"2024-01-27T12:05:55.094877Z","shell.execute_reply":"2024-01-27T12:05:55.101839Z"},"trusted":true}},{"cell_type":"markdown","source":"x_values, y_values = zip(*image_sizes)\nplt.title('x_values')\nplt.hist(x_values,bins=100)\nplt.show()\nplt.title('y_values')\nplt.hist(y_values,bins=100)\nplt.show()","metadata":{"_uuid":"9a282160-4ece-42b9-a511-559618624f01","_cell_guid":"5c42afe9-b4a1-4671-b9b2-1612329b7b77","execution":{"iopub.status.busy":"2024-01-27T12:05:55.109600Z","iopub.execute_input":"2024-01-27T12:05:55.110230Z","iopub.status.idle":"2024-01-27T12:05:56.106594Z","shell.execute_reply.started":"2024-01-27T12:05:55.110192Z","shell.execute_reply":"2024-01-27T12:05:56.105464Z"},"trusted":true}},{"cell_type":"markdown","source":"resoulutions above 1000 pixels in one axis are not representative","metadata":{"_uuid":"41fea3a9-ea64-4c21-8a4f-0f1d042dc778","_cell_guid":"8ae27c5c-f2bf-4a43-8ef3-43350b9d7b87","trusted":true}},{"cell_type":"markdown","source":"filtered_data = [(x, y) for x, y in image_sizes if x < 1000 and y < 1000]\n\nx_values, y_values = zip(*filtered_data)\nplt.hist2d(x_values, y_values, bins=(50, 50), cmap='viridis', cmin = 1)\n\nplt.xlim(0, 1000)\nplt.ylim(0, 1000)\n\n# Add color bar for reference\ncbar = plt.colorbar()\ncbar.set_label('Frequency')\n\n# Add labels and title\nplt.xlabel('horizontal')\nplt.ylabel('vertical')\nplt.title('2D Histogram for resolutions')\n\n# Show the plot\nplt.show()","metadata":{"_uuid":"783f1057-b2b7-43a7-ab2a-2a9aa2acb8ac","_cell_guid":"cccd37a9-37fd-41af-801e-b56c822156f9","execution":{"iopub.status.busy":"2024-01-27T12:05:56.108268Z","iopub.execute_input":"2024-01-27T12:05:56.108626Z","iopub.status.idle":"2024-01-27T12:05:56.462920Z","shell.execute_reply.started":"2024-01-27T12:05:56.108593Z","shell.execute_reply":"2024-01-27T12:05:56.461804Z"},"trusted":true}},{"cell_type":"markdown","source":"Most of the images have rectangular shapes with proportions around 5x4 or 3x5 which should be also true in real life scenarions","metadata":{"_uuid":"879efffa-a47c-4889-af60-6f71cdf90ca8","_cell_guid":"730f952f-4d66-4802-8197-be335f662bdd","trusted":true}},{"cell_type":"markdown","source":"# Create a 2D histogram\nhist, x_edges, y_edges, _ = plt.hist2d(x_values, y_values, bins=(30, 30), cmap='inferno', cmin = 1, vmax=30)\n\nplt.xlim(0, 1000)\nplt.ylim(0, 1000)\n\n# Add color bar for reference\ncbar = plt.colorbar()\ncbar.set_label('Frequency')\n\ncbar.set_ticks([0, 2, 4, 6, 10, 20, 30])\n\nplt.xlabel('horizontal')\nplt.ylabel('vertical')\nplt.title('2D Histogram for rare resolutions')\nplt.show()","metadata":{"_uuid":"8d76b822-8f59-4589-8eb7-72ab7013d605","_cell_guid":"cb95b86f-69dd-491d-84f0-454d09291d4d","execution":{"iopub.status.busy":"2024-01-27T12:05:56.464376Z","iopub.execute_input":"2024-01-27T12:05:56.465377Z","iopub.status.idle":"2024-01-27T12:05:56.785870Z","shell.execute_reply.started":"2024-01-27T12:05:56.465338Z","shell.execute_reply":"2024-01-27T12:05:56.784916Z"},"trusted":true}},{"cell_type":"markdown","source":"It can be obserwed that resolutions below 250 and 550 pixels in any axis also appear rarely","metadata":{"_uuid":"ee6063bb-c5f5-4207-85b5-8f2a41e27d8e","_cell_guid":"c2e374f0-f5bf-4651-90f3-b8c2c625e1d4","trusted":true}},{"cell_type":"markdown","source":"### Plotting the distribution of animal breed to check if they are really distributed uniformally","metadata":{"_uuid":"a680cf48-7bc2-4f63-9d39-48e23752ef7d","_cell_guid":"eae9bbf3-79dd-403b-9fe2-b2e1185a48fd","trusted":true}},{"cell_type":"markdown","source":"plt.hist(annotations['classname'], bins=37, edgecolor='black',rwidth=0.5)\nplt.xticks(rotation='vertical')\nplt.xlabel('breed indexes')\nplt.ylabel('Frequency')\nplt.title('Frequency of different breeds in dataset')\nplt.show()","metadata":{"_uuid":"a868c7c5-8010-480d-9cbf-fc55ae19c906","_cell_guid":"0e9c71a6-1c1d-4c01-8a75-b86a7c532c28","execution":{"iopub.status.busy":"2024-01-27T12:05:56.787317Z","iopub.execute_input":"2024-01-27T12:05:56.787684Z","iopub.status.idle":"2024-01-27T12:05:57.338815Z","shell.execute_reply.started":"2024-01-27T12:05:56.787650Z","shell.execute_reply":"2024-01-27T12:05:57.337612Z"},"trusted":true}},{"cell_type":"markdown","source":"The breeds are actually almost uniformally distributed","metadata":{"_uuid":"6affdf19-29e7-4ccd-b58c-c93b6855b8f4","_cell_guid":"ad31c515-9a31-4735-9aa4-14d81796cde8","trusted":true}},{"cell_type":"markdown","source":"# Splitting datasets and creating the dataloaders","metadata":{"_uuid":"9efe1d59-3943-4ea5-ab01-0d8cfea4ca3d","_cell_guid":"b6fed058-bdf1-4cb9-a666-6801541fb8c3","trusted":true}},{"cell_type":"code","source":"def get_dataloaders(annotations, config): \n    train_set_temp, test_annotations = train_test_split(annotations, test_size=0.2, random_state=random_state, stratify=annotations['CLASS-ID'])\n    train_annotations, validation_annotations = train_test_split(train_set_temp, test_size=0.2, random_state=random_state, stratify=train_set_temp['CLASS-ID'])\n\n    train_data = CatsDogsDataset(train_annotations, transform=config.train_transforms)\n    valid_data = CatsDogsDataset(validation_annotations, transform=config.test_transforms)\n    test_data = CatsDogsDataset(test_annotations, transform=config.test_transforms)\n\n    train_loader = DataLoader(dataset=train_data, batch_size=config.batch_size , shuffle=True)\n    valid_loader = DataLoader(dataset=valid_data, batch_size=config.batch_size, shuffle=True)\n    test_loader = DataLoader(dataset=test_data, batch_size=config.batch_size, shuffle=False)\n    \n    return train_loader,  valid_loader, test_loader","metadata":{"_uuid":"7b09690e-55d9-45a4-a758-cd93632a811b","_cell_guid":"3d204d7d-4140-4554-8394-da7d27835371","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-02-05T13:43:54.238073Z","iopub.execute_input":"2024-02-05T13:43:54.238385Z","iopub.status.idle":"2024-02-05T13:43:54.248152Z","shell.execute_reply.started":"2024-02-05T13:43:54.238360Z","shell.execute_reply":"2024-02-05T13:43:54.247241Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"_uuid":"2e2488d5-d2a4-4c4c-bfee-70c6b10acb68","_cell_guid":"ffea4198-5702-4889-bc8b-6e84246b230d","trusted":true}},{"cell_type":"markdown","source":"### Accuracy function","metadata":{"_uuid":"2bed54b5-5fff-40c6-8ca2-b2a4594349cb","_cell_guid":"9409ae66-18bc-4297-9278-bb4081319ef6","trusted":true}},{"cell_type":"code","source":"def my_accuracy(predictions, labels):\n    predictions = torch.argmax(predictions,dim=1)\n    #print(predictions)\n    #print(labels)\n    correct = (predictions == labels)\n    #print(correct)\n    acc = sum(correct) / len(predictions)\n    #print(acc.item())\n    return acc.item()","metadata":{"_uuid":"c6faa626-6dda-4d5e-8c39-a63c93340f40","_cell_guid":"ff039d46-8087-4803-964b-c2f5c8a8f8c9","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-02-05T13:43:54.249434Z","iopub.execute_input":"2024-02-05T13:43:54.249699Z","iopub.status.idle":"2024-02-05T13:43:54.262855Z","shell.execute_reply.started":"2024-02-05T13:43:54.249676Z","shell.execute_reply":"2024-02-05T13:43:54.261896Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Saving checkpoint","metadata":{"_uuid":"a4637c80-ac5c-489e-b4a1-156631578603","_cell_guid":"b97b9e8a-1172-4bdb-b5f3-0f9d3a56ceb4","trusted":true}},{"cell_type":"code","source":"def save_checkpoint(epoch, model, optimizer, loss, config):\n    if epoch%3 == 0:\n        checkpoint = {\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(prefix='modified_fc.'),\n            'optimizer_state_dict': optimizer.state_dict(), # contains information like lr scheduler state\n            'loss': loss,  # Save the current training loss if needed\n        }\n        info = config.get_configuration_info()\n        checkpoint_path = f'/kaggle/working/{epoch}_{info}.pth'\n        torch.save(checkpoint, checkpoint_path)\n        config.last_checkpoint_path = checkpoint_path\n    return","metadata":{"_uuid":"b80a8abc-5349-47d7-83bb-a0c5a1b1120c","_cell_guid":"63936c3b-4f4c-43d0-af07-8faaf7c8d58c","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-02-05T13:43:54.264117Z","iopub.execute_input":"2024-02-05T13:43:54.264473Z","iopub.status.idle":"2024-02-05T13:43:54.272839Z","shell.execute_reply.started":"2024-02-05T13:43:54.264439Z","shell.execute_reply":"2024-02-05T13:43:54.271817Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Training loop","metadata":{"_uuid":"967732e8-2b82-4cbc-91b4-b70863ddbf08","_cell_guid":"6cc568ce-e3b4-4c36-a4bc-aeb7625ec7d4","trusted":true}},{"cell_type":"code","source":"class TrainingManager: # singleton class\n    _instance = None  # Class variable to store the instance\n\n    def __new__(cls, *args, **kwargs):\n        if not cls._instance:\n            cls._instance = super(TrainingManager, cls).__new__(cls, *args, **kwargs)\n        return cls._instance\n    \n    def __init__(self):\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \n        self.net = None\n        self.optimizer = None\n        self.scheduler = None\n        self.criterion = None\n        \n        self.train_loader = None\n        self.valid_loader = None\n        self.test_loader = None\n        self.resume_epoch = None\n        self.training_accuracy_epoch = 0\n        self.validation_accuracy_epoch = 0\n        self.training_loss_epoch = 0\n        self.validation_loss_epoch = 100\n        self.total_train_batches = 0\n        self.total_valid_batches = 0\n        self.resume_epoch = 0\n        self.cnt = 0\n        \n        self.log_interval = 1\n        self.mean_loss = 0.0\n        self.mean_lr = 0.0\n        self.mean_grad_magnitude = 0.0\n        self.termination_counter = 0\n        self.last_validation_loss = 0\n\n    def setup_configuration(self, config, annotations):\n        self.resume_epoch = 0\n        self.net = config.model.to(self.device)\n        self.optimizer = config.optimizer\n        self.scheduler = config.scheduler\n        self.criterion = config.criterion\n        self.train_loader, self.valid_loader, self.test_loader = get_dataloaders(annotations, config)\n        \n        self.total_train_batches = len(self.train_loader)\n        self.total_valid_batches = len(self.valid_loader)\n        \n        if config.last_checkpoint_path != None:\n            checkpoint = torch.load(config.last_checkpoint_path)\n            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n            self.resume_epoch = checkpoint['epoch']\n            # Remove the prefix from the keys\n            state_dict = {k.replace('modified_fc.', ''): v for k, v in checkpoint['model_state_dict'].items()}\n            # It is required after DataParallel wraps the module\n            state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n            self.net.load_state_dict(state_dict)\n            \n        d = next(self.net.parameters()).device\n        if d.type == 'cuda':\n            print(\"Model is on GPU\")\n            self.net = torch.nn.DataParallel(self.net) # if multiple GPUs use them\n        else:\n            print(\"Model is on CPU\")\n                \n    def training(self, config, annotations):\n        num_epochs = 25\n        self.termination_counter = 0\n        self.setup_configuration(config, annotations)\n        self.net.train()\n        for epoch in range(num_epochs - self.resume_epoch):\n            self.training_loss_epoch = 0\n            self.training_accuracy_epoch = 0\n            self.cnt = 0\n\n            for train_features_batch, train_labels_batch in self.train_loader:\n                train_features_batch, train_labels_batch = train_features_batch.to(self.device), train_labels_batch.to(self.device)\n                self.optimizer.zero_grad()\n\n                y_hat = self.net(train_features_batch)\n\n                training_loss = self.criterion(y_hat, train_labels_batch)\n                training_loss.backward()\n                self.optimizer.step()\n\n                self.training_loss_epoch += training_loss.item()\n                train_accuracy = my_accuracy(y_hat, train_labels_batch)\n                self.training_accuracy_epoch += train_accuracy\n                \n                self.cnt += 1\n                self.batch_log_metrics(training_loss)\n                \n            #save_checkpoint(epoch+self.resume_epoch, self.net, self.optimizer, self.training_loss_epoch, config)\n            self.last_validation_loss = self.validation_loss_epoch\n            self.validation_loss_epoch = 0\n            self.validation_accuracy_epoch = 0\n            self.cnt = 0\n\n            for val_features_batch, val_labels_batch in self.valid_loader:\n                val_features_batch, val_labels_batch = val_features_batch.to(self.device), val_labels_batch.to(self.device)\n                with torch.no_grad():\n                    y_hat_val = self.net(val_features_batch)\n                    validation_loss = self.criterion(y_hat_val, val_labels_batch)\n                    self.validation_loss_epoch += validation_loss.item()\n                    val_accuracy = my_accuracy(y_hat_val, val_labels_batch)\n                    self.validation_accuracy_epoch += val_accuracy\n                    self.cnt += 1\n                    \n            self.normalize_metrics()      \n            self.log_metrics()\n            self.print_metrics(epoch + self.resume_epoch)\n            self.scheduler.step(self.validation_loss_epoch)\n            # Early stopping\n            if  (self.validation_accuracy_epoch - self.training_accuracy_epoch < -0.20) and (self.training_loss_epoch - self.validation_loss_epoch < -0.15):\n                save_checkpoint(epoch+self.resume_epoch, self.net, self.optimizer, self.training_loss_epoch, config)\n                print('Early stopping! Overfitting')\n                return\n            if  self.validation_loss_epoch >= self.last_validation_loss:\n                self.termination_counter += 1\n                save_checkpoint(epoch+self.resume_epoch, self.net, self.optimizer, self.training_loss_epoch, config)\n                if self.termination_counter > 3:\n                    print('Early stopping! Overfitting')\n                    return\n            else:\n                self.termination_counter = 0\n        save_checkpoint(epoch+self.resume_epoch, self.net, self.optimizer, self.training_loss_epoch, config)\n        return\n    def normalize_metrics(self):\n            self.training_accuracy_epoch = self.training_accuracy_epoch / self.total_train_batches\n            self.validation_accuracy_epoch = self.validation_accuracy_epoch / self.total_valid_batches\n            self.training_loss_epoch = self.training_loss_epoch / self.total_train_batches\n            self.validation_loss_epoch = self.validation_loss_epoch / self.total_valid_batches\n            \n    def log_metrics(self):\n        wandb.log({f'validation_loss_epoch': self.validation_loss_epoch,\n                   f'training_loss_epoch': self.training_loss_epoch})\n        wandb.log({f'training_accuracy_epoch': self.training_accuracy_epoch,\n                   f'validation_accuracy_epoch': self.validation_accuracy_epoch})\n\n    def print_metrics(self, epoch):\n        print('~~~~~~~~~~~~~~~~~~~~~ Epoch: ', epoch, ' ~~~~~~~~~~~~~~~~~~~~~')\n        print({f'training_loss_epoch': self.training_loss_epoch,\n               f'training_accuracy_epoch': self.training_accuracy_epoch})\n        print({f'validation_loss_epoch': self.validation_loss_epoch,\n               f'validation_accuracy_epoch': self.validation_accuracy_epoch})\n        \n    def batch_log_metrics(self, train_loss):\n        # Calculate mean values every n batches\n        self.mean_loss += train_loss.item()\n        self.mean_lr += self.optimizer.param_groups[0]['lr']\n        self.mean_grad_magnitude += self.calculate_gradient_magnitude()\n\n        if self.cnt % self.log_interval == 0:\n            # Log mean values\n            mean_loss_batch = self.mean_loss / self.log_interval\n            mean_lr_batch = self.mean_lr / self.log_interval\n            mean_grad_magnitude_batch = self.mean_grad_magnitude / self.log_interval\n\n            wandb.log({'training_loss_every_n_batches': mean_loss_batch,\n                       'training_learning_rate_every_n_batches': mean_lr_batch,\n                       'training_gradient_magnitude_every_n_batches': mean_grad_magnitude_batch})\n\n            # Reset mean values\n            self.mean_loss = 0.0\n            self.mean_lr = 0.0\n            self.mean_grad_magnitude = 0.0\n            \n    def calculate_gradient_magnitude(self):\n        # Example implementation of calculating the gradient magnitude\n        total_norm = 0.0\n        for param in self.net.parameters():\n            if param.grad is not None:\n                total_norm += param.grad.data.norm(2).item()\n        return total_norm\n    def evaluate_on_test_dataset(config, annotations):\n        #setup_configuration(self, config, annotations)\n        #self.net.eval()\n        config.model.eval()\n        self.train_loader, self.valid_loader, self.test_loader = get_dataloaders(annotations, config)\n        predictions = []\n        labels = []\n        with torch.no_grad():\n            for inputs_batch, labels_batch in self.test_loader:\n                outputs = model(inputs_batch)\n                predictions.append(outputs)\n                labels.append(labels_batch)\n        print(my_accuracy(predictions,labels))\n        \n    def evaluate_on_test_dataset(self, config, annotations):\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.setup_configuration(config, annotations)\n        self.net.eval()\n        predictions = []\n        labels = []\n        with torch.no_grad():\n            for inputs_batch, labels_batch in self.test_loader:\n                inputs_batch = inputs_batch.to(self.device)\n                labels_batch = labels_batch.tolist()\n                outputs = self.net(inputs_batch)\n                predicted_classes = [torch.argmax(pred).item() for pred in outputs]\n                predictions += predicted_classes\n                labels += labels_batch\n        return accuracy_score(labels, predictions), confusion_matrix(labels, predictions)","metadata":{"_uuid":"420cc670-9d12-4fdf-baf3-a1fc4ba8ce7e","_cell_guid":"75fd7445-fb6e-4112-885c-19f166ad754c","execution":{"iopub.status.busy":"2024-02-05T13:43:54.275492Z","iopub.execute_input":"2024-02-05T13:43:54.275855Z","iopub.status.idle":"2024-02-05T13:43:54.313926Z","shell.execute_reply.started":"2024-02-05T13:43:54.275822Z","shell.execute_reply":"2024-02-05T13:43:54.313062Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Defining models","metadata":{"_uuid":"63e21653-39e1-42f2-9c24-d447dfd03a61","_cell_guid":"6c40ad0a-e194-4d86-a354-d34ddacf9809","trusted":true}},{"cell_type":"markdown","source":"### ResNet101","metadata":{"_uuid":"95c2a756-ddf1-4cfc-a9a7-a1fb9869d7a7","_cell_guid":"e515a9ae-44ec-4e14-b71a-e7fa4e9529c1","trusted":true}},{"cell_type":"code","source":"def get_pretrained_resnet101():\n    model = models.resnet101(weights=torchvision.models.ResNet101_Weights.DEFAULT)\n    num_classes = 37\n    model.fc = nn.Sequential(\n        nn.Linear(model.fc.in_features, num_classes),\n        nn.Softmax(dim=1)\n    )\n    nn.init.xavier_normal_(model.fc[0].weight)\n    nn.init.constant_(model.fc[0].bias, 0)\n    \n    weights = torchvision.models.ResNet101_Weights.DEFAULT\n    preprocess_transforms = weights.transforms()\n    \n    return model, preprocess_transforms","metadata":{"_uuid":"adcfbbc2-844a-4ae1-b6f1-0cf364f48dbc","_cell_guid":"81d61e69-651c-40f6-9241-dc38acb40934","execution":{"iopub.status.busy":"2024-02-05T13:43:54.314975Z","iopub.execute_input":"2024-02-05T13:43:54.315306Z","iopub.status.idle":"2024-02-05T13:43:54.327986Z","shell.execute_reply.started":"2024-02-05T13:43:54.315271Z","shell.execute_reply":"2024-02-05T13:43:54.327083Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"passed_config = {\n        'optimizer': 'sgd',\n        'learning_rate': {\n            'sgd': 0.01,\n            'adam': 0.0001,\n        },\n        'batch_size': 64,\n    }","metadata":{"_uuid":"8b0d9253-f9d3-46a8-bdf7-f7c1bba9e7c7","_cell_guid":"3a882d0b-7f35-4a30-ac61-14d799aee814","execution":{"iopub.status.busy":"2024-02-05T13:43:54.329153Z","iopub.execute_input":"2024-02-05T13:43:54.329428Z","iopub.status.idle":"2024-02-05T13:43:54.338422Z","shell.execute_reply.started":"2024-02-05T13:43:54.329405Z","shell.execute_reply":"2024-02-05T13:43:54.337485Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',\n    'name': 'final_tuning_ResNet101',\n    \"metric\": {\"goal\": \"minimize\", \"name\": \"validation_loss_epoch\"},\n    'parameters': {\n        'model': {'values': ['ResNet101']},\n        'optimizer': {'values': ['sgd', 'adam']},\n        'learning_rate': {'min': 0.0001, 'max': 0.07},\n        'batch_size': {'values': [32, 64]},\n    }\n}","metadata":{"_uuid":"6b812fb1-bee5-48c0-8c6e-16e313ec8c64","_cell_guid":"efa3a7b3-9752-444d-bd1c-c0a9da65a910","execution":{"iopub.status.busy":"2024-02-05T13:43:54.339471Z","iopub.execute_input":"2024-02-05T13:43:54.339859Z","iopub.status.idle":"2024-02-05T13:43:54.349279Z","shell.execute_reply.started":"2024-02-05T13:43:54.339833Z","shell.execute_reply":"2024-02-05T13:43:54.348452Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#initialize_wandb(sweep_config)\n#print(wandb.config)","metadata":{"_uuid":"13fbeb00-c025-4571-9697-a1e47517055c","_cell_guid":"332ac1e1-d0c8-439c-9feb-25f080ad8332","execution":{"iopub.status.busy":"2024-02-05T13:43:54.350432Z","iopub.execute_input":"2024-02-05T13:43:54.350783Z","iopub.status.idle":"2024-02-05T13:43:54.363174Z","shell.execute_reply.started":"2024-02-05T13:43:54.350749Z","shell.execute_reply":"2024-02-05T13:43:54.362204Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"74d527f8-6efe-4090-9a1d-54280263d7af","_cell_guid":"6f01a231-f65c-4774-a861-4903d57ced0b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def start_training_with_sweep():\n    print(wandb.config)\n    print(\"*\")\n    model, preprocess_transforms = get_pretrained_resnet101()\n    traning_config = configuration(wandb.config, model, preprocess_transforms)\n    manager = TrainingManager()\n    manager.training(traning_config, annotations)","metadata":{"_uuid":"7bd1f441-f280-403d-a46c-31cfe9985e8d","_cell_guid":"d1b937ea-843a-43f2-ab3b-71baaa83734b","execution":{"iopub.status.busy":"2024-02-05T13:43:54.364422Z","iopub.execute_input":"2024-02-05T13:43:54.364773Z","iopub.status.idle":"2024-02-05T13:43:54.372928Z","shell.execute_reply.started":"2024-02-05T13:43:54.364740Z","shell.execute_reply":"2024-02-05T13:43:54.372079Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"initialize_wandb(sweep_config)\nsweep_id = wandb.sweep(sweep=sweep_config, project=\"cats&dogs_ML&DL_project\")\nprint(wandb.config)\nwandb.agent(sweep_id, function=start_training_with_sweep, count=20)","metadata":{"_uuid":"db4dba4f-326b-41b5-8732-b8199756c4b5","_cell_guid":"a3848d77-c012-46cf-9799-cb80a56d8dd2","execution":{"iopub.status.busy":"2024-02-05T13:43:54.374127Z","iopub.execute_input":"2024-02-05T13:43:54.374823Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjerzyjerzu\u001b[0m (\u001b[33mjerze\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240205_134356-14rhtf4l</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jerze/uncategorized/runs/14rhtf4l' target=\"_blank\">worldly-puddle-109</a></strong> to <a href='https://wandb.ai/jerze/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jerze/uncategorized' target=\"_blank\">https://wandb.ai/jerze/uncategorized</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jerze/uncategorized/runs/14rhtf4l' target=\"_blank\">https://wandb.ai/jerze/uncategorized/runs/14rhtf4l</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"name":"stdout","text":"Create sweep with ID: 5de3bz4p\nSweep URL: https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p\n{}\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tdqe3mcp with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.057675771560222806\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: ResNet101\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n","output_type":"stream"},{"name":"stdout","text":"VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))\n<IPython.core.display.HTML object>\n<IPython.core.display.HTML object>\n{}\n*\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet101-cd907fc2.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-cd907fc2.pth\n100%|██████████| 171M/171M [00:00<00:00, 274MB/s] \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240205_134457-tdqe3mcp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/tdqe3mcp' target=\"_blank\">silvery-sweep-1</a></strong> to <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/tdqe3mcp' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/tdqe3mcp</a>"},"metadata":{}},{"name":"stdout","text":"loading parameters\nbatch\nlr\noptimizer\nloaded parameters\ngetting optimizer\nadam\ngot optimizer\nModel is on GPU\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  0  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6136058625720797, 'training_accuracy_epoch': 0.02317862628268547}\n{'validation_loss_epoch': 3.6114711890349516, 'validation_accuracy_epoch': 0.028153153186714328}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  1  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6135798473747407, 'training_accuracy_epoch': 0.022328286146631047}\n{'validation_loss_epoch': 3.612875442247133, 'validation_accuracy_epoch': 0.02533783783783784}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  2  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6119993981860934, 'training_accuracy_epoch': 0.025935374149659865}\n{'validation_loss_epoch': 3.6117061473227836, 'validation_accuracy_epoch': 0.028153153186714328}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  3  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6125153262598984, 'training_accuracy_epoch': 0.02423469387755102}\n{'validation_loss_epoch': 3.6109381173108077, 'validation_accuracy_epoch': 0.028716216216216218}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  4  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6117342621290764, 'training_accuracy_epoch': 0.02487930655479431}\n{'validation_loss_epoch': 3.6117831565238334, 'validation_accuracy_epoch': 0.024493243243243243}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  5  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6127981815208385, 'training_accuracy_epoch': 0.025729646690848734}\n{'validation_loss_epoch': 3.61632734376031, 'validation_accuracy_epoch': 0.02787162162162162}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  6  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.61395255724589, 'training_accuracy_epoch': 0.020209293381697465}\n{'validation_loss_epoch': 3.614346626642588, 'validation_accuracy_epoch': 0.024493243243243243}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  7  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.614107691511816, 'training_accuracy_epoch': 0.023391211316699072}\n{'validation_loss_epoch': 3.611960443290504, 'validation_accuracy_epoch': 0.02646396399752514}\nEpoch 00008: reducing learning rate of group 0 to 2.8838e-02.\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  8  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6112951826887065, 'training_accuracy_epoch': 0.02699829931972789}\n{'validation_loss_epoch': 3.6096360554566256, 'validation_accuracy_epoch': 0.033783783783783786}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  9  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.611815021151588, 'training_accuracy_epoch': 0.03360215052455461}\n{'validation_loss_epoch': 3.607407047941878, 'validation_accuracy_epoch': 0.03856981988694217}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  10  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6119123299916587, 'training_accuracy_epoch': 0.03104427254118887}\n{'validation_loss_epoch': 3.6104981899261475, 'validation_accuracy_epoch': 0.036599099132660275}\nEarly stopping! Overfitting\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>▃▂▄▃▃▄▁▃▅█▇</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>▃▁▇▇▁▁▂▁▁▁▁▁▁▁▂▁▁▁▃▁▂▂▁▁▁█▂▁▂▁▃▄▂▂▁▁▁▁▂▃</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>█████████████████████████████▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_epoch</td><td>▇▇▃▄▂▅██▁▂▃</td></tr><tr><td>training_loss_every_n_batches</td><td>▇▇▇▇▆▇▆▇▇▆▇▇▇▆▇▇▇▇▇▁▇█▇▆▇▇▇▇█▇▆▆▇▇█▂▇▁█▆</td></tr><tr><td>validation_accuracy_epoch</td><td>▃▁▃▃▁▃▁▂▆█▇</td></tr><tr><td>validation_loss_epoch</td><td>▄▅▄▄▄█▆▅▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>0.03104</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>0.00498</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>0.02884</td></tr><tr><td>training_loss_epoch</td><td>3.61191</td></tr><tr><td>training_loss_every_n_batches</td><td>3.6152</td></tr><tr><td>validation_accuracy_epoch</td><td>0.0366</td></tr><tr><td>validation_loss_epoch</td><td>3.6105</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">silvery-sweep-1</strong> at: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/tdqe3mcp' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/tdqe3mcp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240205_134457-tdqe3mcp/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mey3w6it with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.022109318296587136\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: ResNet101\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n","output_type":"stream"},{"name":"stdout","text":"<wandb.sdk.lib.preinit.PreInitObject object at 0x7e2ed3ef86d0>\n*\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240205_141114-mey3w6it</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/mey3w6it' target=\"_blank\">effortless-sweep-2</a></strong> to <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/mey3w6it' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/mey3w6it</a>"},"metadata":{}},{"name":"stdout","text":"loading parameters\nbatch\nlr\noptimizer\nloaded parameters\ngetting optimizer\nsgd\ngot optimizer\nModel is on GPU\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  0  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.5938762974094702, 'training_accuracy_epoch': 0.14142191571158333}\n{'validation_loss_epoch': 3.5175186960320723, 'validation_accuracy_epoch': 0.3574561413965727}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  1  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.258423747243108, 'training_accuracy_epoch': 0.4852264056334624}\n{'validation_loss_epoch': 2.9786567437021354, 'validation_accuracy_epoch': 0.7088815789473685}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  2  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.0084819117107906, 'training_accuracy_epoch': 0.6724267102576591}\n{'validation_loss_epoch': 2.8781134329344096, 'validation_accuracy_epoch': 0.7935855263157895}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  3  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.910306025195766, 'training_accuracy_epoch': 0.7640107338492935}\n{'validation_loss_epoch': 2.8100204969707288, 'validation_accuracy_epoch': 0.8577302631578947}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  4  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.89477124729672, 'training_accuracy_epoch': 0.7719049695375804}\n{'validation_loss_epoch': 2.809229712737234, 'validation_accuracy_epoch': 0.8560855263157895}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  5  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8915588179150142, 'training_accuracy_epoch': 0.7748610506186614}\n{'validation_loss_epoch': 2.7908162694228325, 'validation_accuracy_epoch': 0.8719846512141981}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  6  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8632239908785433, 'training_accuracy_epoch': 0.8001307756514162}\n{'validation_loss_epoch': 2.7809347478966964, 'validation_accuracy_epoch': 0.8865131578947368}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  7  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.863148392857732, 'training_accuracy_epoch': 0.80102986016789}\n{'validation_loss_epoch': 2.7918530765332674, 'validation_accuracy_epoch': 0.8728070196352506}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  8  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8529723560487903, 'training_accuracy_epoch': 0.809659709801545}\n{'validation_loss_epoch': 2.7782979011535645, 'validation_accuracy_epoch': 0.8824013157894737}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  9  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8564165605081095, 'training_accuracy_epoch': 0.8071804159396404}\n{'validation_loss_epoch': 2.780565387324283, 'validation_accuracy_epoch': 0.8832236842105263}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  10  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.840787288304922, 'training_accuracy_epoch': 0.8206394395312747}\n{'validation_loss_epoch': 2.788853733163131, 'validation_accuracy_epoch': 0.8695175459510401}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  11  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.849291121637499, 'training_accuracy_epoch': 0.8124182643117132}\n{'validation_loss_epoch': 2.7862749601665295, 'validation_accuracy_epoch': 0.8695175459510401}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  12  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.853424346124804, 'training_accuracy_epoch': 0.8071259260177612}\n{'validation_loss_epoch': 2.7704441798360726, 'validation_accuracy_epoch': 0.8876096512141981}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  13  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.848310290156184, 'training_accuracy_epoch': 0.8132628589063078}\n{'validation_loss_epoch': 2.77131724357605, 'validation_accuracy_epoch': 0.8914473684210527}\nEarly stopping! Overfitting\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>▁▅▆▇▇█████████</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>▁▁▁▂▂▃▄▅▅▆▄▅▅▄▄▄▅▄▃▅▄▆▃▄▄▆▄█▅▄▄▃▃▅▃▄▆▄▅▂</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_epoch</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_every_n_batches</td><td>███▇▅▄▃▃▄▂▂▂▃▂▃▂▂▁▁▁▂▂▁▁▂▂▂▂▂▂▁▁▁▁▁▂▂▂▂▁</td></tr><tr><td>validation_accuracy_epoch</td><td>▁▆▇███████████</td></tr><tr><td>validation_loss_epoch</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>0.81326</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>34.49673</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>0.02211</td></tr><tr><td>training_loss_epoch</td><td>2.84831</td></tr><tr><td>training_loss_every_n_batches</td><td>2.87077</td></tr><tr><td>validation_accuracy_epoch</td><td>0.89145</td></tr><tr><td>validation_loss_epoch</td><td>2.77132</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">effortless-sweep-2</strong> at: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/mey3w6it' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/mey3w6it</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240205_141114-mey3w6it/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: trhhka76 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04644151467360942\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: ResNet101\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n","output_type":"stream"},{"name":"stdout","text":"<wandb.sdk.lib.preinit.PreInitObject object at 0x7e2ed0cb6710>\n*\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240205_144149-trhhka76</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/trhhka76' target=\"_blank\">resilient-sweep-3</a></strong> to <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/trhhka76' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/trhhka76</a>"},"metadata":{}},{"name":"stdout","text":"loading parameters\nbatch\nlr\noptimizer\nloaded parameters\ngetting optimizer\nsgd\ngot optimizer\nModel is on GPU\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  0  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.3377371710173938, 'training_accuracy_epoch': 0.36364384451690984}\n{'validation_loss_epoch': 3.047783445667576, 'validation_accuracy_epoch': 0.6196509019748585}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  1  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.206893950092549, 'training_accuracy_epoch': 0.4564406407528183}\n{'validation_loss_epoch': 3.0908426336340002, 'validation_accuracy_epoch': 0.5703828834198617}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  2  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.226043026463515, 'training_accuracy_epoch': 0.4324939652365081}\n{'validation_loss_epoch': 3.0861191234073124, 'validation_accuracy_epoch': 0.5760135135135135}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  3  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.2253905769919053, 'training_accuracy_epoch': 0.4331111476129415}\n{'validation_loss_epoch': 3.0904658613978206, 'validation_accuracy_epoch': 0.5720720726090509}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  4  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.2274874700169986, 'training_accuracy_epoch': 0.4333648778954331}\n{'validation_loss_epoch': 3.0524902279312545, 'validation_accuracy_epoch': 0.6086711722451288}\nEpoch 00005: reducing learning rate of group 0 to 2.3221e-02.\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  5  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.146020388116642, 'training_accuracy_epoch': 0.513111695951345}\n{'validation_loss_epoch': 3.005632890237344, 'validation_accuracy_epoch': 0.6494932432432432}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  6  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.129332751643901, 'training_accuracy_epoch': 0.529268158536379}\n{'validation_loss_epoch': 3.0005868254481136, 'validation_accuracy_epoch': 0.6582207212576995}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  7  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.105367829199551, 'training_accuracy_epoch': 0.5545589202115325}\n{'validation_loss_epoch': 2.9636879998284416, 'validation_accuracy_epoch': 0.6965090100829666}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  8  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.0685935863832228, 'training_accuracy_epoch': 0.5900674782642702}\n{'validation_loss_epoch': 2.9629042406339905, 'validation_accuracy_epoch': 0.6973536046775611}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  9  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.0516400093934974, 'training_accuracy_epoch': 0.6072457207708942}\n{'validation_loss_epoch': 2.9652853785334408, 'validation_accuracy_epoch': 0.6951013513513513}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  10  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.049505501377339, 'training_accuracy_epoch': 0.609817313904665}\n{'validation_loss_epoch': 2.9560106702753015, 'validation_accuracy_epoch': 0.7018581081081081}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  11  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.0541246991579225, 'training_accuracy_epoch': 0.602582564970263}\n{'validation_loss_epoch': 2.955481954523035, 'validation_accuracy_epoch': 0.7041103614343179}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  12  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.0437986023572026, 'training_accuracy_epoch': 0.6143090299197606}\n{'validation_loss_epoch': 2.9465394471142745, 'validation_accuracy_epoch': 0.7139639645009428}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  13  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.0321997606835396, 'training_accuracy_epoch': 0.6274755868781992}\n{'validation_loss_epoch': 2.9466423795029923, 'validation_accuracy_epoch': 0.7122747753117535}\nEarly stopping! Overfitting\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>▁▃▃▃▃▅▅▆▇▇█▇██</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>▁▃▅▆▃█▇▄▄▅▇▃▄▆▆▃▅▅▃▇▄▄▄▅▄▃▃▇▃▄▆▂▄▃▂▃▄▂▂▄</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>██████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_epoch</td><td>█▅▅▅▅▄▃▃▂▁▁▂▁▁</td></tr><tr><td>training_loss_every_n_batches</td><td>█▆▂▄▄▅▆▄▅▃▄▄▅▅▃▄▄▂▃▄▃▃▃▃▄▃▃▄▁▃▂▃▁▁▃▄▃▂▃▁</td></tr><tr><td>validation_accuracy_epoch</td><td>▃▁▁▁▃▅▅▇▇▇▇███</td></tr><tr><td>validation_loss_epoch</td><td>▆███▆▄▄▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>0.62748</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>18.9284</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>0.02322</td></tr><tr><td>training_loss_epoch</td><td>3.0322</td></tr><tr><td>training_loss_every_n_batches</td><td>3.00513</td></tr><tr><td>validation_accuracy_epoch</td><td>0.71227</td></tr><tr><td>validation_loss_epoch</td><td>2.94664</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">resilient-sweep-3</strong> at: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/trhhka76' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/trhhka76</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240205_144149-trhhka76/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6dt2o338 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.046143960773363864\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: ResNet101\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n","output_type":"stream"},{"name":"stdout","text":"<wandb.sdk.lib.preinit.PreInitObject object at 0x7e2ed0c9e5f0>\n*\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240205_151310-6dt2o338</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/6dt2o338' target=\"_blank\">icy-sweep-4</a></strong> to <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/6dt2o338' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/6dt2o338</a>"},"metadata":{}},{"name":"stdout","text":"loading parameters\nbatch\nlr\noptimizer\nloaded parameters\ngetting optimizer\nadam\ngot optimizer\nModel is on GPU\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  0  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6127423176894315, 'training_accuracy_epoch': 0.020903716216216218}\n{'validation_loss_epoch': 3.612959309628135, 'validation_accuracy_epoch': 0.02549342105263158}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  1  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6119277992764034, 'training_accuracy_epoch': 0.022592905405405407}\n{'validation_loss_epoch': 3.6116315314644263, 'validation_accuracy_epoch': 0.02631578947368421}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  2  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6118993340311825, 'training_accuracy_epoch': 0.022592905405405407}\n{'validation_loss_epoch': 3.6107521433579293, 'validation_accuracy_epoch': 0.027138157894736843}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  3  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6121825946343913, 'training_accuracy_epoch': 0.021353258474453074}\n{'validation_loss_epoch': 3.610961412128649, 'validation_accuracy_epoch': 0.02631578947368421}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  4  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.612080226073394, 'training_accuracy_epoch': 0.02153716216216216}\n{'validation_loss_epoch': 3.6116231240724264, 'validation_accuracy_epoch': 0.026589912411413695}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  5  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6122166788255847, 'training_accuracy_epoch': 0.02195945945945946}\n{'validation_loss_epoch': 3.6108428553531042, 'validation_accuracy_epoch': 0.0276864035741279}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  6  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6119729312690527, 'training_accuracy_epoch': 0.01900337837837838}\n{'validation_loss_epoch': 3.6115557520013106, 'validation_accuracy_epoch': 0.02850877199518053}\nEpoch 00007: reducing learning rate of group 0 to 2.3072e-02.\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  7  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.611341763187099, 'training_accuracy_epoch': 0.023015202702702704}\n{'validation_loss_epoch': 3.611566091838636, 'validation_accuracy_epoch': 0.02631578947368421}\nEarly stopping! Overfitting\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>▄▇▇▅▅▆▁█</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>▆▂█▁▂▁▂▁▁▁▁▅▁▂▇▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>███████████████████████████████████▁▁▁▁▁</td></tr><tr><td>training_loss_epoch</td><td>█▄▄▅▅▅▄▁</td></tr><tr><td>training_loss_every_n_batches</td><td>▇▇▆▆▆▆█▁▆▆▆▆▅▆▆▆▇▅▆▆▅▇▆▆▆▆▆▆▇▇▆▆▆▆▅▆▆▅▆▇</td></tr><tr><td>validation_accuracy_epoch</td><td>▁▃▅▃▄▆█▃</td></tr><tr><td>validation_loss_epoch</td><td>█▄▁▂▄▁▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>0.02302</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>0.00456</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>0.02307</td></tr><tr><td>training_loss_epoch</td><td>3.61134</td></tr><tr><td>training_loss_every_n_batches</td><td>3.61398</td></tr><tr><td>validation_accuracy_epoch</td><td>0.02632</td></tr><tr><td>validation_loss_epoch</td><td>3.61157</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">icy-sweep-4</strong> at: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/6dt2o338' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/6dt2o338</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240205_151310-6dt2o338/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6shcpczb with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02379107616933932\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: ResNet101\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n","output_type":"stream"},{"name":"stdout","text":"<wandb.sdk.lib.preinit.PreInitObject object at 0x7e2ed4bf52d0>\n*\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240205_153042-6shcpczb</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/6shcpczb' target=\"_blank\">atomic-sweep-5</a></strong> to <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/6shcpczb' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/6shcpczb</a>"},"metadata":{}},{"name":"stdout","text":"loading parameters\nbatch\nlr\noptimizer\nloaded parameters\ngetting optimizer\nadam\ngot optimizer\nModel is on GPU\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  0  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6114884872694275, 'training_accuracy_epoch': 0.02364864864864865}\n{'validation_loss_epoch': 3.6119837384474907, 'validation_accuracy_epoch': 0.0276864035741279}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  1  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.611693501472473, 'training_accuracy_epoch': 0.027674095453442755}\n{'validation_loss_epoch': 3.6111355580781637, 'validation_accuracy_epoch': 0.02549342105263158}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  2  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.611541309872189, 'training_accuracy_epoch': 0.025984906264253566}\n{'validation_loss_epoch': 3.6128422084607577, 'validation_accuracy_epoch': 0.018092105263157895}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  3  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.611574066651834, 'training_accuracy_epoch': 0.025773757615604916}\n{'validation_loss_epoch': 3.6101401228653756, 'validation_accuracy_epoch': 0.03125}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  4  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.60802457461486, 'training_accuracy_epoch': 0.033797406264253566}\n{'validation_loss_epoch': 3.610739130722849, 'validation_accuracy_epoch': 0.03042763157894737}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  5  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6085966438860506, 'training_accuracy_epoch': 0.03759808193992924}\n{'validation_loss_epoch': 3.6079772271608053, 'validation_accuracy_epoch': 0.03316885977983475}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  6  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.607544631571383, 'training_accuracy_epoch': 0.03844267653452384}\n{'validation_loss_epoch': 3.607169088564421, 'validation_accuracy_epoch': 0.034265350942548956}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  7  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.606032632492684, 'training_accuracy_epoch': 0.03613366387985848}\n{'validation_loss_epoch': 3.605169421748111, 'validation_accuracy_epoch': 0.036732456205706844}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  8  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6045403673842147, 'training_accuracy_epoch': 0.03992071707506437}\n{'validation_loss_epoch': 3.6015687490764416, 'validation_accuracy_epoch': 0.04413377199518053}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  9  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.601838195646131, 'training_accuracy_epoch': 0.041650773705662905}\n{'validation_loss_epoch': 3.6006758714977063, 'validation_accuracy_epoch': 0.04139254399036106}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  10  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6009167722753577, 'training_accuracy_epoch': 0.044988284642631944}\n{'validation_loss_epoch': 3.5996952307851693, 'validation_accuracy_epoch': 0.04550438609562422}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  11  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.600527621604301, 'training_accuracy_epoch': 0.04370777027027027}\n{'validation_loss_epoch': 3.6016183652375875, 'validation_accuracy_epoch': 0.04276315789473684}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  12  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.599766856915242, 'training_accuracy_epoch': 0.046718341273230476}\n{'validation_loss_epoch': 3.5958196991368343, 'validation_accuracy_epoch': 0.05263157894736842}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  13  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.6012203467858805, 'training_accuracy_epoch': 0.044974662162162164}\n{'validation_loss_epoch': 3.600914980235853, 'validation_accuracy_epoch': 0.046875}\nEarly stopping! Overfitting\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>▁▂▂▂▄▅▅▅▆▆▇▇█▇</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>▁▁▁▁▁▁▂▁▁▃▂▁▃▁▃▂▂▃▂▂▂▁▃▂▂▂▂▂▂▂▂▂▂▂▂▃▂▃▃█</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_epoch</td><td>████▆▆▆▅▄▂▂▁▁▂</td></tr><tr><td>training_loss_every_n_batches</td><td>▆▆▆▆▆▆▆▆▇▆▆▆▃▃██▆▄▇▅▆▆▆▅▆▆▄▅▇▅▇▄▄▇▆▆▅▁▄▂</td></tr><tr><td>validation_accuracy_epoch</td><td>▃▂▁▄▃▄▄▅▆▆▇▆█▇</td></tr><tr><td>validation_loss_epoch</td><td>█▇█▇▇▆▆▅▃▃▃▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>0.04497</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>0.07285</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>0.02379</td></tr><tr><td>training_loss_epoch</td><td>3.60122</td></tr><tr><td>training_loss_every_n_batches</td><td>3.61982</td></tr><tr><td>validation_accuracy_epoch</td><td>0.04688</td></tr><tr><td>validation_loss_epoch</td><td>3.60091</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">atomic-sweep-5</strong> at: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/6shcpczb' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/6shcpczb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240205_153042-6shcpczb/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xlpy5lhi with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.026059992327453\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: ResNet101\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n","output_type":"stream"},{"name":"stdout","text":"<wandb.sdk.lib.preinit.PreInitObject object at 0x7e2ed4afb040>\n*\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240205_160035-xlpy5lhi</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/xlpy5lhi' target=\"_blank\">celestial-sweep-6</a></strong> to <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/xlpy5lhi' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/xlpy5lhi</a>"},"metadata":{}},{"name":"stdout","text":"loading parameters\nbatch\nlr\noptimizer\nloaded parameters\ngetting optimizer\nsgd\ngot optimizer\nModel is on GPU\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  0  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.5790636958302677, 'training_accuracy_epoch': 0.14771550772963343}\n{'validation_loss_epoch': 3.4493753031680456, 'validation_accuracy_epoch': 0.3673245624492043}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  1  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.1643828797984765, 'training_accuracy_epoch': 0.5716815606967823}\n{'validation_loss_epoch': 2.854821054559005, 'validation_accuracy_epoch': 0.8262061413965727}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  2  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.9221909883859993, 'training_accuracy_epoch': 0.7517777351108758}\n{'validation_loss_epoch': 2.811593670594065, 'validation_accuracy_epoch': 0.8555372827931454}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  3  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8906403812202246, 'training_accuracy_epoch': 0.7783960877238093}\n{'validation_loss_epoch': 2.8066814824154505, 'validation_accuracy_epoch': 0.8506030722668296}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  4  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.9081663247701286, 'training_accuracy_epoch': 0.755224226294337}\n{'validation_loss_epoch': 2.821137729444002, 'validation_accuracy_epoch': 0.843201756477356}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  5  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8889598943091728, 'training_accuracy_epoch': 0.7735532908826261}\n{'validation_loss_epoch': 2.7945277314437065, 'validation_accuracy_epoch': 0.8665021940281517}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  6  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8887242207656034, 'training_accuracy_epoch': 0.7792134365519962}\n{'validation_loss_epoch': 2.7786866991143477, 'validation_accuracy_epoch': 0.8917214933194613}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  7  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8656941652297974, 'training_accuracy_epoch': 0.797188317453539}\n{'validation_loss_epoch': 2.7705733901575993, 'validation_accuracy_epoch': 0.8928179835018358}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  8  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.852648470852826, 'training_accuracy_epoch': 0.810293155747491}\n{'validation_loss_epoch': 2.761069235048796, 'validation_accuracy_epoch': 0.9035087729755201}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  9  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.863386070406115, 'training_accuracy_epoch': 0.7986663579940796}\n{'validation_loss_epoch': 2.7743021563479773, 'validation_accuracy_epoch': 0.8873355263157895}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  10  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8548270496162207, 'training_accuracy_epoch': 0.8077593719637072}\n{'validation_loss_epoch': 2.763860639772917, 'validation_accuracy_epoch': 0.897203947368421}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  11  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.839274367770633, 'training_accuracy_epoch': 0.8215249019700128}\n{'validation_loss_epoch': 2.772449342828048, 'validation_accuracy_epoch': 0.8895285098176253}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  12  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.843199820131869, 'training_accuracy_epoch': 0.8187799695375804}\n{'validation_loss_epoch': 2.7578242703488, 'validation_accuracy_epoch': 0.905701756477356}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  13  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.843677449870754, 'training_accuracy_epoch': 0.8164164665583018}\n{'validation_loss_epoch': 2.766802285846911, 'validation_accuracy_epoch': 0.8917214933194613}\nEarly stopping! Overfitting\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>▁▅▇█▇█████████</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>▁▁▂▂▃▃▅▅▇▃▅█▄▇▃▅▅▆▇▇▄▇▅▇▇▄▆██▇▅▄▆▇█▆▃▅▄▆</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_epoch</td><td>█▄▂▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_every_n_batches</td><td>██▇▆▃▄▃▂▃▂▂▂▂▂▂▂▁▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂▂▂▂</td></tr><tr><td>validation_accuracy_epoch</td><td>▁▇▇▇▇▇████████</td></tr><tr><td>validation_loss_epoch</td><td>█▂▂▁▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>0.81642</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>32.55459</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>0.02606</td></tr><tr><td>training_loss_epoch</td><td>2.84368</td></tr><tr><td>training_loss_every_n_batches</td><td>2.86676</td></tr><tr><td>validation_accuracy_epoch</td><td>0.89172</td></tr><tr><td>validation_loss_epoch</td><td>2.7668</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">celestial-sweep-6</strong> at: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/xlpy5lhi' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/xlpy5lhi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240205_160035-xlpy5lhi/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ald60ed2 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.020342289804041555\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: ResNet101\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n","output_type":"stream"},{"name":"stdout","text":"<wandb.sdk.lib.preinit.PreInitObject object at 0x7e2ed3efb010>\n*\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240205_163010-ald60ed2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/ald60ed2' target=\"_blank\">silvery-sweep-7</a></strong> to <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/ald60ed2' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/ald60ed2</a>"},"metadata":{}},{"name":"stdout","text":"loading parameters\nbatch\nlr\noptimizer\nloaded parameters\ngetting optimizer\nsgd\ngot optimizer\nModel is on GPU\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  0  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.594311975144051, 'training_accuracy_epoch': 0.12620559052841082}\n{'validation_loss_epoch': 3.529814318606728, 'validation_accuracy_epoch': 0.3623903519228885}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  1  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.290136279286565, 'training_accuracy_epoch': 0.4738243786064354}\n{'validation_loss_epoch': 2.939739315133346, 'validation_accuracy_epoch': 0.756578947368421}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  2  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.973248504303597, 'training_accuracy_epoch': 0.7091938208889317}\n{'validation_loss_epoch': 2.8433588931435034, 'validation_accuracy_epoch': 0.8300438617405138}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  3  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8987670556918994, 'training_accuracy_epoch': 0.7752152351108758}\n{'validation_loss_epoch': 2.7937230059975073, 'validation_accuracy_epoch': 0.8739035098176253}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  4  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8674659439035364, 'training_accuracy_epoch': 0.8014794024261268}\n{'validation_loss_epoch': 2.7768569745515523, 'validation_accuracy_epoch': 0.8873355263157895}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  5  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8603692376935803, 'training_accuracy_epoch': 0.8047624230384827}\n{'validation_loss_epoch': 2.7758804622449373, 'validation_accuracy_epoch': 0.8895285098176253}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  6  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.836800807231181, 'training_accuracy_epoch': 0.829943602149551}\n{'validation_loss_epoch': 2.7418457583377234, 'validation_accuracy_epoch': 0.9273574571860465}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  7  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.825031866898408, 'training_accuracy_epoch': 0.8402626417778634}\n{'validation_loss_epoch': 2.7484122577466463, 'validation_accuracy_epoch': 0.912828947368421}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  8  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8167516701930277, 'training_accuracy_epoch': 0.8481023859333348}\n{'validation_loss_epoch': 2.748721398805317, 'validation_accuracy_epoch': 0.9081688617405138}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  9  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.834097627046946, 'training_accuracy_epoch': 0.8282135459216865}\n{'validation_loss_epoch': 2.7427285721427515, 'validation_accuracy_epoch': 0.9194078947368421}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  10  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8232953870618664, 'training_accuracy_epoch': 0.8403035088165386}\n{'validation_loss_epoch': 2.7465929357629073, 'validation_accuracy_epoch': 0.9144736842105263}\nEpoch 00011: reducing learning rate of group 0 to 1.0171e-02.\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  11  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8071688768025993, 'training_accuracy_epoch': 0.8548455206123559}\n{'validation_loss_epoch': 2.7291214340611507, 'validation_accuracy_epoch': 0.9295504406878823}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  12  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.793640613555908, 'training_accuracy_epoch': 0.8671330100781208}\n{'validation_loss_epoch': 2.733356990312275, 'validation_accuracy_epoch': 0.9290021940281517}\nEarly stopping! Overfitting\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>▁▄▇▇▇▇███████</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>▁▁▁▂▂▄▄▄▄▃▃▄▃▆▆▅▇▅▄▆▄▄▅▄█▃▄▄▃▅▃▅▆▅▄▆▅▄▅▅</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>██████████████████████████████████▁▁▁▁▁▁</td></tr><tr><td>training_loss_epoch</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_every_n_batches</td><td>███▇▆▄▄▃▃▃▂▂▃▂▂▃▂▂▂▂▂▂▂▂▃▁▂▂▁▂▂▁▂▂▁▂▁▂▁▂</td></tr><tr><td>validation_accuracy_epoch</td><td>▁▆▇▇▇████████</td></tr><tr><td>validation_loss_epoch</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>0.86713</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>35.64826</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>0.01017</td></tr><tr><td>training_loss_epoch</td><td>2.79364</td></tr><tr><td>training_loss_every_n_batches</td><td>2.78748</td></tr><tr><td>validation_accuracy_epoch</td><td>0.929</td></tr><tr><td>validation_loss_epoch</td><td>2.73336</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">silvery-sweep-7</strong> at: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/ald60ed2' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/ald60ed2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240205_163010-ald60ed2/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: iid4tpov with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01895447688718646\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: ResNet101\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n","output_type":"stream"},{"name":"stdout","text":"<wandb.sdk.lib.preinit.PreInitObject object at 0x7e2eb0cf09d0>\n*\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240205_165734-iid4tpov</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/iid4tpov' target=\"_blank\">gentle-sweep-8</a></strong> to <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/iid4tpov' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/iid4tpov</a>"},"metadata":{}},{"name":"stdout","text":"loading parameters\nbatch\nlr\noptimizer\nloaded parameters\ngetting optimizer\nsgd\ngot optimizer\nModel is on GPU\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  0  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.5999471400235152, 'training_accuracy_epoch': 0.11434039876267717}\n{'validation_loss_epoch': 3.5610333618364836, 'validation_accuracy_epoch': 0.29523026315789475}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  1  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.327373659288561, 'training_accuracy_epoch': 0.4631239095249692}\n{'validation_loss_epoch': 2.9780752658843994, 'validation_accuracy_epoch': 0.7305372827931454}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  2  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.98154536131266, 'training_accuracy_epoch': 0.7169790751225239}\n{'validation_loss_epoch': 2.804545101366545, 'validation_accuracy_epoch': 0.8714364045544675}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  3  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.884732681351739, 'training_accuracy_epoch': 0.787673005381146}\n{'validation_loss_epoch': 2.7918308283153332, 'validation_accuracy_epoch': 0.8788377203439411}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  4  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.867286537144635, 'training_accuracy_epoch': 0.799143145213256}\n{'validation_loss_epoch': 2.791076747994674, 'validation_accuracy_epoch': 0.8708881578947368}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  5  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8583384526742472, 'training_accuracy_epoch': 0.8081952913387401}\n{'validation_loss_epoch': 2.7897193682821175, 'validation_accuracy_epoch': 0.8752741248984086}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  6  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8586471982904382, 'training_accuracy_epoch': 0.8058590341258693}\n{'validation_loss_epoch': 2.7929752123983285, 'validation_accuracy_epoch': 0.8695175459510401}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  7  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8571259717683533, 'training_accuracy_epoch': 0.8081680471832687}\n{'validation_loss_epoch': 2.7651716031526266, 'validation_accuracy_epoch': 0.8958333354247244}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  8  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8278802568848067, 'training_accuracy_epoch': 0.837122656203605}\n{'validation_loss_epoch': 2.769847217359041, 'validation_accuracy_epoch': 0.890625}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  9  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8307500272183805, 'training_accuracy_epoch': 0.8339554264738753}\n{'validation_loss_epoch': 2.7817439781992057, 'validation_accuracy_epoch': 0.881030703845777}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  10  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.839632176064156, 'training_accuracy_epoch': 0.8220766122276718}\n{'validation_loss_epoch': 2.7565156409614966, 'validation_accuracy_epoch': 0.9054276315789473}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  11  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8365068145700403, 'training_accuracy_epoch': 0.8261429264738753}\n{'validation_loss_epoch': 2.747738160585102, 'validation_accuracy_epoch': 0.9147478091089349}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  12  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8310447512446224, 'training_accuracy_epoch': 0.8295485506186614}\n{'validation_loss_epoch': 2.75553486221715, 'validation_accuracy_epoch': 0.9046052631578947}\nEarly stopping! Overfitting\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>▁▄▇██████████</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>▁▁▁▁▂▂▃▄▅▅▆▅▇▅▅▄▃▄▅▅▆▅▄▄█▅▅▅▇▇▆▅▄▆█▅▄▆▄▇</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_epoch</td><td>█▆▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_every_n_batches</td><td>████▆▄▄▃▃▂▃▂▃▂▂▁▁▁▂▃▂▂▁▂▂▃▂▂▁▁▁▂▂▂▂▂▁▂▂▂</td></tr><tr><td>validation_accuracy_epoch</td><td>▁▆████▇██████</td></tr><tr><td>validation_loss_epoch</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>0.82955</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>17.98096</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>0.01895</td></tr><tr><td>training_loss_epoch</td><td>2.83104</td></tr><tr><td>training_loss_every_n_batches</td><td>2.78368</td></tr><tr><td>validation_accuracy_epoch</td><td>0.90461</td></tr><tr><td>validation_loss_epoch</td><td>2.75553</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">gentle-sweep-8</strong> at: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/iid4tpov' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/iid4tpov</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240205_165734-iid4tpov/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8ljia6cn with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02683765530552515\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: ResNet101\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n","output_type":"stream"},{"name":"stdout","text":"<wandb.sdk.lib.preinit.PreInitObject object at 0x7e2ed0cb4550>\n*\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240205_172440-8ljia6cn</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/8ljia6cn' target=\"_blank\">fearless-sweep-9</a></strong> to <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/8ljia6cn' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/8ljia6cn</a>"},"metadata":{}},{"name":"stdout","text":"loading parameters\nbatch\nlr\noptimizer\nloaded parameters\ngetting optimizer\nsgd\ngot optimizer\nModel is on GPU\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  0  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.5778316807102515, 'training_accuracy_epoch': 0.1790608650929219}\n{'validation_loss_epoch': 3.3817342833468786, 'validation_accuracy_epoch': 0.4895833354247244}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  1  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.1205188551464595, 'training_accuracy_epoch': 0.6029179378135784}\n{'validation_loss_epoch': 2.877543248628315, 'validation_accuracy_epoch': 0.7957785098176253}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  2  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.955684977608758, 'training_accuracy_epoch': 0.7186682643117132}\n{'validation_loss_epoch': 2.8461920211189673, 'validation_accuracy_epoch': 0.8199013157894737}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  3  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.935174262201464, 'training_accuracy_epoch': 0.7316777464505788}\n{'validation_loss_epoch': 2.832868914855154, 'validation_accuracy_epoch': 0.828125}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  4  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.914164504489383, 'training_accuracy_epoch': 0.7496934935853288}\n{'validation_loss_epoch': 2.8057303930583752, 'validation_accuracy_epoch': 0.859100878238678}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  5  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.9062547748153276, 'training_accuracy_epoch': 0.7577580100781208}\n{'validation_loss_epoch': 2.810013168736508, 'validation_accuracy_epoch': 0.8508771940281517}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  6  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8950530645009636, 'training_accuracy_epoch': 0.7684993453927942}\n{'validation_loss_epoch': 2.8066100948735286, 'validation_accuracy_epoch': 0.852521930870257}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  7  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8982259647266284, 'training_accuracy_epoch': 0.7646578026784433}\n{'validation_loss_epoch': 2.812560897124441, 'validation_accuracy_epoch': 0.8492324571860465}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  8  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.902673872741493, 'training_accuracy_epoch': 0.7552106034111332}\n{'validation_loss_epoch': 2.8011717796325684, 'validation_accuracy_epoch': 0.8607456150807833}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  9  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8922289029971973, 'training_accuracy_epoch': 0.7686968719637072}\n{'validation_loss_epoch': 2.820308070433767, 'validation_accuracy_epoch': 0.8423793880563033}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  10  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8937919526486784, 'training_accuracy_epoch': 0.7659246945703352}\n{'validation_loss_epoch': 2.8073954080280505, 'validation_accuracy_epoch': 0.852796052631579}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  11  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8955868514808447, 'training_accuracy_epoch': 0.767641128720464}\n{'validation_loss_epoch': 2.807903628600271, 'validation_accuracy_epoch': 0.8519736842105263}\nEarly stopping! Overfitting\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>▁▆▇█████████</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>▁▁▁▂▃▄▃▃▄▅▆▅▃█▂▃▄▂▆▄▇▃▅▆▅▅▆▂▅▄▅▇▇▆▄▅▆▄▅▆</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_epoch</td><td>█▃▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_every_n_batches</td><td>███▇▅▄▄▂▂▂▂▃▂▃▂▁▃▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▂▂▁▂▁▂▂▂</td></tr><tr><td>validation_accuracy_epoch</td><td>▁▇▇▇████████</td></tr><tr><td>validation_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>0.76764</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>28.89072</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>0.02684</td></tr><tr><td>training_loss_epoch</td><td>2.89559</td></tr><tr><td>training_loss_every_n_batches</td><td>2.90351</td></tr><tr><td>validation_accuracy_epoch</td><td>0.85197</td></tr><tr><td>validation_loss_epoch</td><td>2.8079</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fearless-sweep-9</strong> at: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/8ljia6cn' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/8ljia6cn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240205_172440-8ljia6cn/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rzusyey5 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02250976598190853\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: ResNet101\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n","output_type":"stream"},{"name":"stdout","text":"<wandb.sdk.lib.preinit.PreInitObject object at 0x7e2ed1d421a0>\n*\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240205_174945-rzusyey5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/rzusyey5' target=\"_blank\">exalted-sweep-10</a></strong> to <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/rzusyey5' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/rzusyey5</a>"},"metadata":{}},{"name":"stdout","text":"loading parameters\nbatch\nlr\noptimizer\nloaded parameters\ngetting optimizer\nsgd\ngot optimizer\nModel is on GPU\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  0  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.595784200204385, 'training_accuracy_epoch': 0.1323016563782821}\n{'validation_loss_epoch': 3.521827459335327, 'validation_accuracy_epoch': 0.3070175443824969}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  1  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.294494068300402, 'training_accuracy_epoch': 0.4551138837595244}\n{'validation_loss_epoch': 2.9721349038575826, 'validation_accuracy_epoch': 0.7371162301615665}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  2  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.9793934242145435, 'training_accuracy_epoch': 0.712122656203605}\n{'validation_loss_epoch': 2.8283550990255257, 'validation_accuracy_epoch': 0.8429276315789473}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  3  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.909957247811395, 'training_accuracy_epoch': 0.7585753589063078}\n{'validation_loss_epoch': 2.810880184173584, 'validation_accuracy_epoch': 0.8511513157894737}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  4  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.891229342769932, 'training_accuracy_epoch': 0.7748065606967823}\n{'validation_loss_epoch': 2.7919584199001917, 'validation_accuracy_epoch': 0.8717105263157895}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  5  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.879618493286339, 'training_accuracy_epoch': 0.7864606034111332}\n{'validation_loss_epoch': 2.7944936752319336, 'validation_accuracy_epoch': 0.8648574571860465}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  6  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8537851539818018, 'training_accuracy_epoch': 0.8107835650444031}\n{'validation_loss_epoch': 2.7674913657338998, 'validation_accuracy_epoch': 0.896929825607099}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  7  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8486805960938737, 'training_accuracy_epoch': 0.8140802093454309}\n{'validation_loss_epoch': 2.7704287077251233, 'validation_accuracy_epoch': 0.8911732466597306}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  8  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.839787222243644, 'training_accuracy_epoch': 0.8221719699936945}\n{'validation_loss_epoch': 2.7798259885687577, 'validation_accuracy_epoch': 0.8804824571860465}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  9  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8416397217157723, 'training_accuracy_epoch': 0.8208369661021877}\n{'validation_loss_epoch': 2.757997650849192, 'validation_accuracy_epoch': 0.9037828947368421}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  10  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.843506133234179, 'training_accuracy_epoch': 0.8179217520597819}\n{'validation_loss_epoch': 2.757184467817608, 'validation_accuracy_epoch': 0.9024122827931454}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  11  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8344681198532515, 'training_accuracy_epoch': 0.829071763399485}\n{'validation_loss_epoch': 2.766515618876407, 'validation_accuracy_epoch': 0.8922697368421053}\nEarly stopping! Overfitting\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>▁▄▇▇▇███████</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>▁▁▁▂▃▄▄▅▄▃▇▆▅▃▇▇█▇▇▆█▅▅▇▄▆▇▅▅▅▇▇▅▄▆▃▆▅█▅</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_epoch</td><td>█▅▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_every_n_batches</td><td>███▇▆▅▄▃▃▂▂▂▂▂▂▂▃▂▂▂▂▂▃▁▂▂▂▁▁▁▂▂▁▂▂▁▁▁▁▂</td></tr><tr><td>validation_accuracy_epoch</td><td>▁▆▇▇████████</td></tr><tr><td>validation_loss_epoch</td><td>█▃▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>0.82907</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>17.51988</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>0.02251</td></tr><tr><td>training_loss_epoch</td><td>2.83447</td></tr><tr><td>training_loss_every_n_batches</td><td>2.8964</td></tr><tr><td>validation_accuracy_epoch</td><td>0.89227</td></tr><tr><td>validation_loss_epoch</td><td>2.76652</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">exalted-sweep-10</strong> at: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/rzusyey5' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/rzusyey5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240205_174945-rzusyey5/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9b9t7ggb with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.024254882405332377\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: ResNet101\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n","output_type":"stream"},{"name":"stdout","text":"<wandb.sdk.lib.preinit.PreInitObject object at 0x7e2ed1d78f70>\n*\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240205_181450-9b9t7ggb</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/9b9t7ggb' target=\"_blank\">scarlet-sweep-11</a></strong> to <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/9b9t7ggb' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/9b9t7ggb</a>"},"metadata":{}},{"name":"stdout","text":"loading parameters\nbatch\nlr\noptimizer\nloaded parameters\ngetting optimizer\nsgd\ngot optimizer\nModel is on GPU\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  0  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.585335654181403, 'training_accuracy_epoch': 0.15030378143529635}\n{'validation_loss_epoch': 3.476905207884939, 'validation_accuracy_epoch': 0.3415570180667074}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  1  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.2202391302263416, 'training_accuracy_epoch': 0.5077035201562418}\n{'validation_loss_epoch': 2.9173278934077214, 'validation_accuracy_epoch': 0.7700109670036718}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  2  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.956588854660859, 'training_accuracy_epoch': 0.7228639931292147}\n{'validation_loss_epoch': 2.8221622266267476, 'validation_accuracy_epoch': 0.8470394736842105}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  3  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.902454002483471, 'training_accuracy_epoch': 0.7693303179096531}\n{'validation_loss_epoch': 2.8144619339390804, 'validation_accuracy_epoch': 0.850328947368421}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  4  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.896848949226173, 'training_accuracy_epoch': 0.7674572250327548}\n{'validation_loss_epoch': 2.8158504460987293, 'validation_accuracy_epoch': 0.8481359670036718}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  5  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.893540508038289, 'training_accuracy_epoch': 0.7716257080838487}\n{'validation_loss_epoch': 2.811867312381142, 'validation_accuracy_epoch': 0.8473135985826191}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  6  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.890687836183084, 'training_accuracy_epoch': 0.7711352979814684}\n{'validation_loss_epoch': 2.8165226986533716, 'validation_accuracy_epoch': 0.8459429835018358}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  7  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8886068350559957, 'training_accuracy_epoch': 0.7735396688048904}\n{'validation_loss_epoch': 2.82087126531099, 'validation_accuracy_epoch': 0.8401864045544675}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  8  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.887279803688462, 'training_accuracy_epoch': 0.7742139817895116}\n{'validation_loss_epoch': 2.807023098594264, 'validation_accuracy_epoch': 0.8538925459510401}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  9  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.88229484493668, 'training_accuracy_epoch': 0.7765366169246467}\n{'validation_loss_epoch': 2.8021281769401147, 'validation_accuracy_epoch': 0.8604714933194613}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  10  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.8769774952450313, 'training_accuracy_epoch': 0.7832116387985848}\n{'validation_loss_epoch': 2.804301487772088, 'validation_accuracy_epoch': 0.8552631578947368}\nEarly stopping! Overfitting\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>▁▅▇████████</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>▁▁▁▂▂▃▃▄▄▃▅▃▄▅▅▃▃▆▃▄█▃▅▃▄▇▃▄▃▄▅▅▄▅▆▄▅▅▅▅</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_epoch</td><td>█▄▂▁▁▁▁▁▁▁▁</td></tr><tr><td>training_loss_every_n_batches</td><td>████▆▅▅▃▃▃▂▂▂▃▃▂▂▂▂▂▂▂▂▂▃▂▂▂▁▁▂▂▂▂▂▂▂▁▂▂</td></tr><tr><td>validation_accuracy_epoch</td><td>▁▇█████████</td></tr><tr><td>validation_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training_accuracy_epoch</td><td>0.78321</td></tr><tr><td>training_gradient_magnitude_every_n_batches</td><td>25.71805</td></tr><tr><td>training_learning_rate_every_n_batches</td><td>0.02425</td></tr><tr><td>training_loss_epoch</td><td>2.87698</td></tr><tr><td>training_loss_every_n_batches</td><td>3.00815</td></tr><tr><td>validation_accuracy_epoch</td><td>0.85526</td></tr><tr><td>validation_loss_epoch</td><td>2.8043</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">scarlet-sweep-11</strong> at: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/9b9t7ggb' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/9b9t7ggb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240205_181450-9b9t7ggb/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: moez940a with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.022022429723317652\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: ResNet101\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n","output_type":"stream"},{"name":"stdout","text":"<wandb.sdk.lib.preinit.PreInitObject object at 0x7e2ed2deab30>\n*\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240205_183756-moez940a</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/moez940a' target=\"_blank\">golden-sweep-12</a></strong> to <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/sweeps/5de3bz4p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/moez940a' target=\"_blank\">https://wandb.ai/jerze/cats%26dogs_ML%26DL_project/runs/moez940a</a>"},"metadata":{}},{"name":"stdout","text":"loading parameters\nbatch\nlr\noptimizer\nloaded parameters\ngetting optimizer\nsgd\ngot optimizer\nModel is on GPU\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  0  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.5881423692445495, 'training_accuracy_epoch': 0.15020842407200788}\n{'validation_loss_epoch': 3.474503015217028, 'validation_accuracy_epoch': 0.3459429835018359}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  1  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 3.2490236888060697, 'training_accuracy_epoch': 0.491363338522009}\n{'validation_loss_epoch': 2.904381425757157, 'validation_accuracy_epoch': 0.7897478091089349}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  2  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.9553980666237907, 'training_accuracy_epoch': 0.7296207498859715}\n{'validation_loss_epoch': 2.82947039604187, 'validation_accuracy_epoch': 0.8410087729755201}\nimage has Alpha channel\nimage has Alpha channel\nimage has Alpha channel\n~~~~~~~~~~~~~~~~~~~~~ Epoch:  3  ~~~~~~~~~~~~~~~~~~~~~\n{'training_loss_epoch': 2.9143798383506567, 'training_accuracy_epoch': 0.7574787486243892}\n{'validation_loss_epoch': 2.818576122585096, 'validation_accuracy_epoch': 0.8459429835018358}\nimage has Alpha channel\n","output_type":"stream"}]},{"cell_type":"code","source":"manager = TrainingManager()\nmanager.training(traning_config, annotations)","metadata":{"_uuid":"885def7c-54e8-4459-8c58-419ac4060d36","_cell_guid":"7974534f-ee8a-4830-8f53-92dd1d201fff","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\n#optimizer = optim.Adam(model.parameters(), lr=0.0001)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True, min_lr=5e-4, factor=0.3)\nconfig = configuration(batch_size, model, optimizer, scheduler, preprocess_transforms, costum_transforms)\nprint(config.get_configuration_info())","metadata":{"_uuid":"618e6531-b772-4f69-9ca0-6d93cf00a517","_cell_guid":"ca2fba95-7176-48cb-bf57-d22c3bd86456","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"initialize_wandb(config)","metadata":{"_uuid":"98625201-3f41-4da9-bdff-09f624af9ba4","_cell_guid":"c5e62387-3f8e-4c66-ad6d-4e4cdba7f3fb","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"manager = TrainingManager()\nmanager.training(config, annotations)","metadata":{"_uuid":"9f17e995-d40b-48bc-8d18-e71bbf4f4f82","_cell_guid":"21f71aa4-7b66-40f6-9fe9-1070be4d0505","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config.last_checkpoint_path = \"/kaggle/input/checkpoint/21_ResNet_SGD_Batch64_lr0.01.pth\"\nmanager = TrainingManager()\nacc, confusion_mat = manager.evaluate_on_test_dataset(config, annotations)\nprint(acc)","metadata":{"_uuid":"60502f16-c14c-42cb-85bf-e547a99db699","_cell_guid":"27e44661-9807-47be-9a0b-050a849cae6d","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusion_mat)","metadata":{"_uuid":"e29fa0e9-696f-41fa-8059-f39514f76818","_cell_guid":"b8c78d58-49d9-4f7a-a7ed-8edc17f08616","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_on_test_dataset(config, annotations):\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        #setup_configuration(self, config, annotations)\n        #self.net.eval()\n        config.model.eval()\n        train_loader, valid_loader, test_loader = get_dataloaders(annotations, config)\n        predictions = []\n        labels = []\n        with torch.no_grad():\n            for inputs_batch, labels_batch in test_loader:\n                inputs_batch = inputs_batch.to(device)\n                labels_batch = labels_batch.tolist()\n                outputs = model(inputs_batch)\n                predicted_classes = [torch.argmax(pred).item() for pred in outputs]\n                predicted_classes = predicted_classes\n                predictions += predicted_classes\n                labels += labels_batch\n            #print(predictions)\n            #print(labels)\n            confusion_mat = confusion_matrix(labels, predictions)\n        print(accuracy_score(labels, predictions))\n        print(confusion_mat)","metadata":{"_uuid":"8c63a8e6-1326-4225-a11d-25d9de3ce0fe","_cell_guid":"f5a6b487-62b2-4b0d-b3e7-b6e7756f19bb","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_on_test_dataset(config,annotations)","metadata":{"_uuid":"2e4cbd2d-07e2-4ab7-a01c-5e27c786ce82","_cell_guid":"a546e78c-0c69-4878-942d-2c143b2b9024","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ResNet18","metadata":{"_uuid":"0149dd9a-0ed2-4d7a-b2fc-d7c0aeb6b181","_cell_guid":"c719a467-8d42-4e9d-9d97-ba5297f7a5d9","trusted":true}},{"cell_type":"markdown","source":"resnet18model = models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n\nnum_classes = 37\nresnet18model.fc = nn.Sequential(\n    nn.Linear(resnet18model.fc.in_features, num_classes),\n    nn.Softmax(dim=1)\n)\nnn.init.xavier_normal_(resnet18model.fc[0].weight)\nnn.init.constant_(resnet18model.fc[0].bias, 0)","metadata":{"_uuid":"54181a10-1604-401f-ab99-df0ced7170cf","_cell_guid":"3574e3ba-116d-4b8d-8e76-8c8f2d1444f6","execution":{"iopub.status.busy":"2024-01-28T21:50:55.233334Z","iopub.status.idle":"2024-01-28T21:50:55.233660Z","shell.execute_reply.started":"2024-01-28T21:50:55.233500Z","shell.execute_reply":"2024-01-28T21:50:55.233516Z"},"trusted":true}},{"cell_type":"markdown","source":"costum_transforms = torchvision.transforms.Compose([\n    #transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(p=0.4),\n  ])\nweights = torchvision.models.ResNet18_Weights.DEFAULT\npreprocess_transforms = weights.transforms()","metadata":{"_uuid":"39f13cff-1e9b-40f4-a3a7-47f5cc44b2b5","_cell_guid":"f61dc69c-c4a7-4bfe-b405-cc1e850ff0de","execution":{"iopub.status.busy":"2024-01-28T21:50:55.235245Z","iopub.status.idle":"2024-01-28T21:50:55.235573Z","shell.execute_reply.started":"2024-01-28T21:50:55.235414Z","shell.execute_reply":"2024-01-28T21:50:55.235429Z"},"trusted":true}},{"cell_type":"markdown","source":"batch_size = 64\n#optimizer = torch.optim.SGD(resnet18model.parameters(), lr=0.8)\noptimizer = optim.Adam(resnet18model.parameters(), lr=0.0001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True, min_lr=7e-6, factor=0.5)\nconfig = configuration(batch_size, resnet18model, optimizer, scheduler, preprocess_transforms, costum_transforms)\nprint(config.get_configuration_info())","metadata":{"_uuid":"4d207070-7acf-473a-93f3-cbc7e79f19db","_cell_guid":"f64b4833-5bab-43e0-acd4-f50bd7f1acba","execution":{"iopub.status.busy":"2024-01-28T21:50:55.236651Z","iopub.status.idle":"2024-01-28T21:50:55.236951Z","shell.execute_reply.started":"2024-01-28T21:50:55.236800Z","shell.execute_reply":"2024-01-28T21:50:55.236814Z"},"trusted":true}},{"cell_type":"markdown","source":"config.get_configuration_dictionary()","metadata":{"_uuid":"667b51cd-9625-4bde-bebb-6c21a6137d30","_cell_guid":"7b477871-a876-4035-807f-8eaa13a62065","execution":{"iopub.status.busy":"2024-01-28T21:50:55.238671Z","iopub.status.idle":"2024-01-28T21:50:55.239118Z","shell.execute_reply.started":"2024-01-28T21:50:55.238885Z","shell.execute_reply":"2024-01-28T21:50:55.238906Z"},"trusted":true}},{"cell_type":"markdown","source":"initialize_wandb(config)","metadata":{"_uuid":"85a36426-ab75-4df1-ba4e-6758a6558bbd","_cell_guid":"3f265652-2cb3-4d2c-9264-24cf14ec8077","execution":{"iopub.status.busy":"2024-01-28T21:50:55.240486Z","iopub.status.idle":"2024-01-28T21:50:55.240935Z","shell.execute_reply.started":"2024-01-28T21:50:55.240707Z","shell.execute_reply":"2024-01-28T21:50:55.240729Z"},"trusted":true}},{"cell_type":"markdown","source":"manager = TrainingManager()\nmanager.training(config, annotations)","metadata":{"_uuid":"a4e1bd2e-bee5-472a-9fcb-1361c07e7cdb","_cell_guid":"decc90ee-9b35-48ef-af9b-776939b022d2","execution":{"iopub.status.busy":"2024-01-28T21:50:55.242090Z","iopub.status.idle":"2024-01-28T21:50:55.242550Z","shell.execute_reply.started":"2024-01-28T21:50:55.242320Z","shell.execute_reply":"2024-01-28T21:50:55.242343Z"},"trusted":true}},{"cell_type":"markdown","source":"mobileNet_model = torchvision.models.mobilenet_v2(pretrained=True)\npreprocess_transforms = mobileNet_model.transforms()\n\nnum_classes = 37\nmobileNet_model.classifier[1] = nn.Sequential(\n    nn.Linear(mobileNet_model.last_channel, num_classes),\n    nn.Softmax(dim=1)\n)\nmobileNet_model.classifier[1][0].apply(initialize_weights)","metadata":{"_uuid":"c4655ba1-b3b9-4a67-983e-a0c856d6f653","_cell_guid":"433ea531-b02c-4aa7-8075-c08e8b022133","execution":{"iopub.status.busy":"2024-01-28T21:50:55.243821Z","iopub.status.idle":"2024-01-28T21:50:55.244281Z","shell.execute_reply.started":"2024-01-28T21:50:55.244036Z","shell.execute_reply":"2024-01-28T21:50:55.244057Z"},"trusted":true}},{"cell_type":"markdown","source":"batch_size = 64\noptimizer = torch.optim.SGD(resnet18model.parameters(), lr=0.000001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=20, verbose=True, min_lr=7e-5, factor=0.5)\nconfig2 = configuration(batch_size, mobileNet_model, optimizer, scheduler, preprocess_transforms, costum_transforms)\n\nprint(config2.get_configuration_info())","metadata":{"_uuid":"0b6bf8be-f101-4abb-82ee-366b77137f43","_cell_guid":"51ba2bf8-270f-4ba0-9f73-b2df9c6a790b","execution":{"iopub.status.busy":"2024-01-28T21:50:55.245391Z","iopub.status.idle":"2024-01-28T21:50:55.245837Z","shell.execute_reply.started":"2024-01-28T21:50:55.245602Z","shell.execute_reply":"2024-01-28T21:50:55.245623Z"},"trusted":true}},{"cell_type":"markdown","source":"preprocess_transforms","metadata":{"_uuid":"d39759e4-b234-4088-bdd3-b35773c0c2f2","_cell_guid":"2dc77120-ab80-482e-af88-84b7fef69b43","execution":{"iopub.status.busy":"2024-01-28T21:50:55.246835Z","iopub.status.idle":"2024-01-28T21:50:55.247288Z","shell.execute_reply.started":"2024-01-28T21:50:55.247043Z","shell.execute_reply":"2024-01-28T21:50:55.247066Z"},"trusted":true}},{"cell_type":"code","source":"","metadata":{"_uuid":"b82cfa4b-c6ab-4e89-bd17-1a0dfc0dbf44","_cell_guid":"6c3edf04-2c13-4b8e-8821-39ef1c639c39","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"manager = TrainingManager()\nmanager.training(config2, annotations)","metadata":{"_uuid":"e80aaeee-e176-4d84-9bdc-f86836b67739","_cell_guid":"87001051-235c-42c2-b448-6d71fbfb5094","execution":{"iopub.status.busy":"2024-01-28T21:50:55.248588Z","iopub.status.idle":"2024-01-28T21:50:55.249033Z","shell.execute_reply.started":"2024-01-28T21:50:55.248810Z","shell.execute_reply":"2024-01-28T21:50:55.248831Z"},"trusted":true}},{"cell_type":"markdown","source":"","metadata":{"_uuid":"6a072d61-77be-4feb-8445-139974e52926","_cell_guid":"de911ca3-e130-4950-9722-f065db05c33a","trusted":true}}]}